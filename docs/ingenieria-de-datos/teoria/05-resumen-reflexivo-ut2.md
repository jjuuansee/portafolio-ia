---
title: "Resumen Reflexivo UT2 ‚Äî Data Quality & Limpieza"
date: 2025-12-02
author: "Juan Paroli"
---

# üßπ Reflexi√≥n sobre UT2: Data Quality & Limpieza

## ¬øDe qu√© trat√≥ esta unidad y qu√© problemas buscaba resolver?

La **UT2** se enfoc√≥ en un problema cr√≠tico que enfrentan todos los proyectos de datos reales: **los datos nunca vienen perfectos**. Hay valores faltantes, outliers, escalas inconsistentes, y lo m√°s peligroso: **sesgos ocultos** que pueden hacer que un modelo aparentemente funcional sea completamente injusto o inv√°lido.

El problema central de esta unidad fue: **¬øc√≥mo preparar datos de forma honesta y reproducible para que los modelos que construyamos sean confiables?** Esto implica no solo "llenar huecos" con imputaci√≥n, sino entender **por qu√©** faltan los datos, **c√≥mo** afectan al an√°lisis, y **qu√©** transformaciones aplicar sin introducir sesgos o fugas de informaci√≥n.

En mis palabras, esta unidad me ense√±√≥ que **limpiar datos es una ciencia, no un arte**. No se trata de aplicar `.fillna(0)` a todo y esperar lo mejor; se trata de tomar decisiones fundamentadas, documentarlas, y construir pipelines que sean **reproducibles** y **auditables**.

---

## Conceptos y t√©cnicas clave que incorpor√©

### 1. **Clasificaci√≥n de Missing Data: MCAR, MAR, MNAR**

Uno de los conceptos m√°s importantes fue entender que **no todos los datos faltantes son iguales**. La clasificaci√≥n de Little & Rubin distingue tres tipos:

- **MCAR (Missing Completely At Random)**: Los faltantes no dependen de nada. Ejemplo: un sensor que falla aleatoriamente.
- **MAR (Missing At Random)**: Los faltantes dependen de otras variables observadas. Ejemplo: `Garage Area` falta porque no hay garage (`Garage Type` = None).
- **MNAR (Missing Not At Random)**: Los faltantes dependen del propio valor. Ejemplo: personas con altos ingresos que no reportan sus datos.

**Ejemplo del portafolio**: En el [an√°lisis de Ames Housing](../ejercicios/ut2-missing-data-detection/missing_data.md), cre√© missing sint√©tico para simular cada tipo:

```python
# MCAR: 10% aleatorio en Year Built
# MAR: Garage Area falta cuando Garage Type = None
# MNAR: SalePrice falta para precios > percentil 90
```

Esta clasificaci√≥n gui√≥ mi estrategia de imputaci√≥n: para MCAR us√© mediana global, para MAR us√© mediana por grupo (vecindario), y para MNAR cre√© un **flag binario** indicando que el dato estaba ausente (porque su ausencia es informaci√≥n en s√≠ misma).

---

### 2. **Data Leakage y Pipelines Honestos**

El **data leakage** es quiz√°s el error m√°s peligroso en ML porque **infla m√©tricas falsamente** y el modelo falla en producci√≥n. Ocurre cuando informaci√≥n del test "filtra" al train.

**Ejemplo del portafolio**: En la [pr√°ctica de Feature Scaling](../ejercicios/ut2-ames-housing/ames_housing.md), demostr√© tres formas de escalar datos:

| M√©todo | ¬øHay leakage? | R¬≤ | MAE (USD) |
|--------|---------------|-----|-----------|
| Escalar todo y luego split | **S√≠** ‚ö†Ô∏è | 0.1846 | 36,914 |
| Split ‚Üí fit en train ‚Üí transform | No ‚úÖ | 0.1957 | 36,443 |
| Pipeline (Scaler‚ÜíModelo) | No ‚úÖ | 0.1957 | 36,443 |

El m√©todo 1 "contamina" el scaler con informaci√≥n del test (medias, desv√≠os), produciendo m√©tricas optimistas pero inv√°lidas. La soluci√≥n es usar **Pipelines de scikit-learn** que automatizan el orden correcto:

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PowerTransformer
from sklearn.neighbors import KNeighborsRegressor

pipeline = Pipeline([
    ('transformer', PowerTransformer(method='yeo-johnson')),
    ('model', KNeighborsRegressor(n_neighbors=5))
])
```

Esto garantiza que el escalado se ajuste **solo con train** en cada fold de cross-validation.

---

### 3. **Detecci√≥n y mitigaci√≥n de sesgo con Fairlearn**

M√°s all√° de la calidad t√©cnica, esta unidad me introdujo a la **responsabilidad √©tica en ML**. Los modelos pueden perpetuar sesgos hist√≥ricos si no los detectamos activamente.

**Ejemplo del portafolio**: En la [pr√°ctica de sesgo](../ejercicios/ut2-sesgo-ames-housing/sesgo-titanic.md), trabaj√© con dos casos:

**Boston Housing (regresi√≥n)**: El dataset tiene una variable `B` que codifica indirectamente la proporci√≥n de poblaci√≥n afroamericana. Aunque mejora la predicci√≥n (R¬≤ = 0.7112 con `B`), es **√©ticamente problem√°tica**. No debe usarse en producci√≥n.

**Titanic (clasificaci√≥n)**: Detect√© sesgos de g√©nero (+54.8% supervivencia mujeres) y clase (+41.3% 1ra vs 3ra). Apliqu√© mitigaci√≥n con Fairlearn:

| Modelo | Accuracy | DPD (Demographic Parity Difference) |
|--------|----------|-------------------------------------|
| Baseline (RandomForest) | 0.673 | 0.113 |
| Mitigado (ExponentiatedGradient) | 0.617 | **0.035** |

**Trade-off**: Perd√≠ 8.3% de accuracy para ganar 0.079 en equidad. ¬øVale la pena? Depende del dominio. En salud o finanzas, probablemente s√≠.

```python
from fairlearn.reductions import ExponentiatedGradient, DemographicParity

constraint = DemographicParity()
mitigator = ExponentiatedGradient(model_baseline, constraint)
mitigator.fit(X_train, y_train, sensitive_features=sensitive_features_train)
```

---

## ¬øQu√© fue lo que m√°s me cost√≥ y c√≥mo lo destrab√©?

Lo que m√°s me cost√≥ fue **entender cu√°ndo usar cada tipo de scaler** y por qu√© `PowerTransformer` es diferente a los escaladores lineales.

### El problema

En Ames Housing, las distribuciones son muy asim√©tricas:

- `SalePrice`: skew = **1.44**, kurtosis = **6.18**
- `Lot Area`: skew = **12.82**, kurtosis = **265.02**
- `Misc Val`: skew = **22.00**, kurtosis = **566.20**

Los scalers lineales (`StandardScaler`, `MinMaxScaler`, `RobustScaler`) **no corrigen asimetr√≠a**; solo ajustan rango/escala. Esto es un problema para modelos basados en distancia (KNN, SVM) que asumen distribuciones sim√©tricas.

### C√≥mo lo destrab√©

1. **Entend√≠ la teor√≠a**: `PowerTransformer (Yeo-Johnson)` aplica una transformaci√≥n no lineal que "estira" la distribuci√≥n para hacerla m√°s sim√©trica.

2. **Visualic√© el efecto**: Compar√© skew antes y despu√©s:

| Variable | Skew Original | Skew con PowerTransformer |
|----------|--------------|---------------------------|
| SalePrice | 1.44 | **0.08** ‚úÖ |
| Lot Area | 12.82 | **0.10** ‚úÖ |
| Misc Val | 22.00 | 5.05 ‚ö†Ô∏è (masa en 0) |

3. **Identifiqu√© limitaciones**: `Misc Val` tiene **masa en cero** (muchos valores = 0), lo que hace que Yeo-Johnson no funcione bien. Para estas variables, necesito estrategias espec√≠ficas (ej.: transformar solo valores > 0).

**Lecci√≥n clave**: No existe un scaler "universal". La elecci√≥n depende de la **distribuci√≥n de los datos** y del **algoritmo que usar√°s despu√©s**.

---

## Una tarea en detalle: An√°lisis de calidad de datos en Ames Housing

### ¬øQu√© hice?

En la [pr√°ctica de Missing Data Detection](../ejercicios/ut2-missing-data-detection/missing_data.md), realic√© un an√°lisis completo de calidad de datos:

1. **Exploraci√≥n inicial**: 2930 registros, 82 columnas, 29 con valores faltantes.
2. **Clasificaci√≥n de missing**: Identifiqu√© patrones MCAR, MAR, MNAR.
3. **Detecci√≥n de outliers**: Compar√© IQR vs Z-Score.
4. **Estrategias de imputaci√≥n**: Compar√© simple (media/mediana/moda) vs smart (por grupo).
5. **Pipeline reproducible**: Cre√© un `ColumnTransformer` modular.

### ¬øQu√© aprend√≠?

1. **Visualizaci√≥n de missing patterns**: Ver el porcentaje de faltantes por columna revel√≥ que `Pool QC` tiene >95% missing (pr√°cticamente inutilizable).

2. **IQR vs Z-Score**: IQR detecta m√°s outliers en distribuciones sesgadas porque no asume normalidad. En `Lot Area`: IQR encontr√≥ 127 outliers, Z-Score solo 29.

3. **Imputaci√≥n inteligente preserva estructura**: Imputar `Year Built` con mediana por `Neighborhood` + `House Style` mantiene las relaciones entre variables mejor que la mediana global.

4. **Pipelines modulares son esenciales**: El `ColumnTransformer` me permiti√≥ aplicar transformaciones diferentes a num√©ricas y categ√≥ricas en un solo paso reproducible.

### ¬øQu√© mejorar√≠a?

1. **Imputaci√≥n m√°s sofisticada**: Probar `KNNImputer` o `IterativeImputer` (MICE) para capturar relaciones multivariadas.

2. **Variables con >90% missing**: Evaluar si eliminarlas o crear features derivadas (ej.: `has_pool` binario en lugar de `Pool QC`).

3. **Validaci√≥n del impacto**: Medir c√≥mo cambian las m√©tricas del modelo final con diferentes estrategias de imputaci√≥n.

4. **Documentaci√≥n autom√°tica**: Generar un "data quality report" con pandas-profiling o Great Expectations.

---

## ¬øEn qu√© tipo de proyecto real usar√≠a esto?

### 1. **Sector salud: Predicci√≥n de readmisi√≥n hospitalaria**

**Problema**: Predecir si un paciente ser√° readmitido en 30 d√≠as.

**Aplicaci√≥n UT2**:

- **Missing data**: Datos de laboratorio (MNAR: no se pidieron porque el m√©dico no lo consider√≥ necesario), datos demogr√°ficos (MCAR: errores de entrada).
- **Outliers**: Valores de glucosa o presi√≥n arterial extremos pueden ser errores de medici√≥n o casos reales cr√≠ticos.
- **Sesgo**: Modelos que predicen peor para minor√≠as si los datos hist√≥ricos tienen subrepresentaci√≥n.
- **Leakage**: Usar diagn√≥stico del alta para predecir readmisi√≥n (informaci√≥n futura).

**Estrategia**: Pipeline con imputaci√≥n por grupo (diagn√≥stico principal), flag de missing para MNAR, auditor√≠a de equidad por edad/g√©nero/raza.

---

### 2. **Fintech: Scoring crediticio**

**Problema**: Evaluar riesgo de impago de cr√©ditos.

**Aplicaci√≥n UT2**:

- **Missing data**: Historial crediticio (MNAR: personas sin historial son m√°s riesgosas pero no por eso deben ser penalizadas).
- **Sesgo hist√≥rico**: Modelos entrenados con datos que reflejan discriminaci√≥n pasada pueden perpetuarla.
- **Leakage**: Usar comportamiento de pago del cr√©dito actual para predecir impago.

**Estrategia**: Imputaci√≥n cuidadosa sin penalizar ausencia de historial, auditor√≠a de Demographic Parity y Equalized Odds por g√©nero/etnia, pipelines con validaci√≥n temporal (train en meses anteriores, test en meses posteriores).

---

### 3. **Retail: Predicci√≥n de demanda**

**Problema**: Predecir ventas para optimizar inventario.

**Aplicaci√≥n UT2**:

- **Missing data**: Ventas = 0 porque no hab√≠a stock (MNAR: la demanda exist√≠a pero no se registr√≥).
- **Outliers**: Picos por promociones o eventos especiales (outliers leg√≠timos que no deben eliminarse).
- **Escalado**: Variables con escalas muy diferentes (unidades vendidas vs precio vs temperatura).

**Estrategia**: Imputar demanda latente cuando hay stockout, mantener outliers de promociones con flag, `RobustScaler` para features con outliers leg√≠timos.

---

### 4. **Recursos Humanos: Predicci√≥n de rotaci√≥n**

**Problema**: Predecir qu√© empleados dejar√°n la empresa.

**Aplicaci√≥n UT2**:

- **Missing data**: Encuestas de satisfacci√≥n no completadas (MNAR: empleados insatisfechos pueden evitar completarlas).
- **Sesgo**: Modelos que predicen mayor rotaci√≥n para ciertos grupos demogr√°ficos pueden ser discriminatorios.
- **Leakage**: Usar fecha de renuncia o motivo de salida para predecir rotaci√≥n.

**Estrategia**: Flag de no-respuesta en encuestas como feature, auditor√≠a de equidad por g√©nero/edad/departamento, validaci√≥n temporal estricta.

---

## Conclusi√≥n

La **UT2** me ense√±√≥ que **la calidad de los datos determina la calidad del modelo**. No importa qu√© tan sofisticado sea el algoritmo; si los datos est√°n mal preparados, el modelo ser√° in√∫til o peligroso.

Los tres pilares de esta unidad fueron:

1. ‚úÖ **Entender el missing data**: No todos los faltantes son iguales (MCAR/MAR/MNAR).
2. ‚úÖ **Prevenir data leakage**: Pipelines honestos con escalado solo en train.
3. ‚úÖ **Auditar sesgos**: Detectar y mitigar inequidades con herramientas como Fairlearn.

Estos conceptos no son opcionales; son **obligatorios** para cualquier proyecto de datos serio. Un modelo que parece funcionar bien pero tiene leakage o sesgo es peor que no tener modelo, porque genera **confianza falsa** en predicciones err√≥neas.

Ahora, cada vez que enfrento un dataset nuevo, mi checklist incluye:

1. ‚úÖ Explorar patrones de missing y clasificarlos
2. ‚úÖ Detectar outliers con IQR/Z-Score seg√∫n distribuci√≥n
3. ‚úÖ Elegir imputaci√≥n seg√∫n el tipo de missing
4. ‚úÖ Usar Pipeline para evitar leakage
5. ‚úÖ Auditar sesgos antes de desplegar

---

## üìö Referencias

- Little, R. J. A., & Rubin, D. B. (2019). *Statistical Analysis with Missing Data*. Wiley.
- van Buuren, S. (2018). *Flexible Imputation of Missing Data*. CRC Press.
- Fairlearn Documentation: https://fairlearn.org/
- Scikit-learn: Preprocessing & Pipeline APIs
- Kaggle: *Ames Housing Dataset*

---

