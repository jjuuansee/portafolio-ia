---
title: "Preparaci√≥n y Enriquecimiento de Datos en Cloud Dataprep"
date: 2025-12-05
author: "Juan Paroli"
---

# üìä‚öôÔ∏è Preparaci√≥n y Enriquecimiento de Datos en Cloud Dataprep

## Contexto

En esta actividad se complet√≥ el lab intermedio **"Creating a Data Transformation Pipeline with Cloud Dataprep" (GSP430)** de Google Cloud Skills Boost. Este lab brind√≥ experiencia pr√°ctica con **Cloud Dataprep (Alteryx Designer Cloud)**, una herramienta visual para explorar, limpiar y transformar datos antes de an√°lisis o carga en data warehouses.

Se construy√≥ un **pipeline completo** que toma datos desde BigQuery, los procesa en Dataprep, y publica los resultados nuevamente en BigQuery.

**Fuente**: [Creating a Data Transformation Pipeline with Cloud Dataprep (GSP430)](https://www.cloudskillsboost.google/focuses/4415)  
**Nivel**: Intermedio  
**Duraci√≥n**: 75 minutos

## üéØ Objetivos

- [x] Entender la interfaz y funcionalidades de Cloud Dataprep
- [x] Conectar datasets de BigQuery como origen y destino
- [x] Explorar calidad de datos con herramientas visuales
- [x] Construir un pipeline de limpieza y enriquecimiento
- [x] Crear columnas calculadas y transformaciones complejas
- [x] Ejecutar un job de Dataprep usando Dataflow
- [x] Exportar resultados a BigQuery
- [x] Comprender el flujo end-to-end BigQuery ‚Üí Dataprep ‚Üí BigQuery

## Actividades (con tiempos estimados)

| Actividad | Tiempo | Resultado esperado |
|-----------|:------:|-------------------|
| Configuraci√≥n inicial | 10m | Dataprep habilitado |
| Creaci√≥n de dataset en BigQuery | 10m | Dataset `ecommerce` creado |
| Conexi√≥n BigQuery ‚Üí Dataprep | 10m | Flow configurado |
| Exploraci√≥n de datos | 15m | Quality profiling realizado |
| Limpieza de datos | 15m | Recipe con transformaciones |
| Enriquecimiento | 15m | Columnas calculadas |
| Ejecuci√≥n del pipeline | 10m | Tabla final en BigQuery |

---

## Desarrollo

### 1. Configuraci√≥n Inicial de Cloud Dataprep

Se cre√≥ la identidad necesaria para Dataprep:

```bash
gcloud beta services identity create --service=dataprep.googleapis.com
```

Luego se accedi√≥ al servicio desde:

```
Navigation Menu ‚Üí Analytics ‚Üí Alteryx Designer Cloud
```

Incluyendo aceptaci√≥n de t√©rminos, permisos, autenticaci√≥n con Qwiklabs y configuraci√≥n del bucket de almacenamiento.

> **Nota**: Cloud Dataprep requiere Google Chrome.

---

### 2. Creaci√≥n de Dataset en BigQuery

Se cre√≥ el dataset `ecommerce` y luego la tabla base con:

```sql
CREATE OR REPLACE TABLE ecommerce.all_sessions_raw_dataprep AS
SELECT *
FROM `data-to-insights.ecommerce.all_sessions_raw`
WHERE date = '20170801';
```

**Resultado**: ~56,000 filas del Google Merchandise Store.

---

### 3. Conexi√≥n de BigQuery a Cloud Dataprep

| Paso | Acci√≥n |
|------|--------|
| 1 | Crear Flow ‚Üí `Ecommerce Analytics Pipeline` |
| 2 | A√±adir dataset desde BigQuery |
| 3 | Seleccionar tabla `all_sessions_raw_dataprep` |

Dataprep analiza autom√°ticamente estructura, tipos y calidad.

---

### 4. Exploraci√≥n Visual de Datos

Dataprep ofrece varias herramientas de exploraci√≥n:

| Herramienta | Funci√≥n |
|-------------|---------|
| **Panel de esquema** | Columnas, tipos y detecci√≥n de inconsistencias |
| **Vista tabular** | Histogramas por columna, outliers y valores faltantes |
| **Panel de sugerencias** | Transformaciones recomendadas autom√°ticamente |

#### Hallazgos clave:

- Varias columnas con valores nulos
- Revenue multiplicado por 1e6
- Tipos de hit diversos (PAGE, EVENT, etc.)
- Datos de sesi√≥n complejos

---

### 5. Limpieza de Datos

#### 5.1 Filtrar por tipo de hit

Se seleccionaron solo visualizaciones de p√°ginas:

```
type = "PAGE"
```

#### 5.2 Eliminar columnas irrelevantes

Se removieron columnas nulas, redundantes o no √∫tiles para el an√°lisis.

---

### 6. Enriquecimiento de Datos

#### 6.1 Crear identificador √∫nico de sesi√≥n

```
unique_session_id = fullVisitorId + "-" + visitId
```

#### 6.2 Etiquetas descriptivas para acciones e-commerce

Se transform√≥ `eCommerceAction_type` (c√≥digos 0‚Äì8) a etiquetas legibles usando **Case Statement**:

| C√≥digo | Etiqueta |
|--------|----------|
| 0 | Unknown |
| 1 | Click through of product lists |
| 2 | Product detail views |
| 3 | Add product(s) to cart |
| 4 | Remove product(s) from cart |
| 5 | Check out |
| 6 | Completed purchase |
| 7 | Refund of purchase |
| 8 | Checkout options |

#### 6.3 Normalizar revenue

```
totalTransactionRevenue1 = DIVIDE(totalTransactionRevenue, 1000000)
```

Nueva columna con tipo **Decimal**.

---

### 7. Ejecuci√≥n del Pipeline en Dataflow

#### Configuraci√≥n del job:

| Par√°metro | Valor |
|-----------|-------|
| Ambiente | Dataflow + BigQuery |
| Acci√≥n | Crear nueva tabla |
| Nombre destino | `revenue_reporting` |
| Opci√≥n | Drop table on every run |

#### Proceso de ejecuci√≥n:

```
1. Validaci√≥n del recipe
2. Compilaci√≥n a Apache Beam
3. Ejecuci√≥n distribuida en Dataflow
4. Escritura en BigQuery
```

**Verificaci√≥n final**: Tabla `revenue_reporting` disponible y correcta en BigQuery.

---

## Conceptos Clave Aprendidos

### Cloud Dataprep

| Caracter√≠stica | Descripci√≥n |
|---------------|-------------|
| Preparaci√≥n visual | Interfaz drag-and-drop para transformaciones |
| Detecci√≥n autom√°tica | Identifica problemas de calidad de datos |
| Transformaciones sin c√≥digo | Accesible para analistas no t√©cnicos |
| Integraci√≥n nativa | Conecta directamente con BigQuery |

### Recipes y Flows

| Componente | Funci√≥n |
|------------|---------|
| **Flow** | Pipeline completo de transformaci√≥n |
| **Recipe** | Pasos individuales de transformaci√≥n |
| **Dataset** | Origen de datos conectado |

### Tipos de transformaciones disponibles

- Filtrado de filas
- Eliminaci√≥n de columnas
- Enriquecimiento (nuevas columnas calculadas)
- Case statements condicionales
- F√≥rmulas personalizadas
- Joins, pivots y agregaciones

### Arquitectura del pipeline

```
BigQuery (origen) ‚Üí Dataprep (transformaci√≥n) ‚Üí Dataflow (ejecuci√≥n) ‚Üí BigQuery (destino)
```

---

## Aplicaciones para Ingenier√≠a de Datos

| √Årea | Aplicaci√≥n |
|------|------------|
| **Machine Learning** | Preparar features, crear datasets limpios, manejar valores faltantes |
| **ETL para Data Warehousing** | Pipelines visuales, reglas de negocio documentadas |
| **Google Analytics** | Limpieza, mapeos descriptivos, reporting avanzado |
| **Data Quality** | Perfilado de columnas, validaci√≥n de valores, auditor√≠as |
| **Colaboraci√≥n** | No-code para analistas, documentaci√≥n visual |

---

## Desaf√≠os y Soluciones

| Desaf√≠o | Soluci√≥n |
|---------|----------|
| Interfaz abrumadora al inicio | Seguir el flujo b√°sico: Flow ‚Üí Recipe ‚Üí Transformaciones |
| Necesidad de usar Chrome | Limitaci√≥n t√©cnica del servicio |
| Transformaciones complejas | Case statements requieren planificaci√≥n previa |
| Jobs lentos en datasets grandes | Utilizar subsets para desarrollo |
| Debugging de transformaciones | Revisar paso a paso con vista previa |

---

## Evidencias

- **Lab completado**: GSP430 - Creating a Data Transformation Pipeline with Cloud Dataprep
- **Plataforma**: [Google Cloud Skills Boost](https://www.cloudskillsboost.google/)
- **Badge obtenido**: ‚úÖ Completado
- **Tabla creada**: `ecommerce.revenue_reporting` en BigQuery

---

## Reflexi√≥n

Este lab demostr√≥ el ciclo completo de preparaci√≥n de datos usando Google Cloud:

### Fortalezas del lab

1. **Pipeline end-to-end**: BigQuery ‚Üí Dataprep ‚Üí Dataflow ‚Üí BigQuery
2. **Datos reales**: Google Merchandise Store con ~56,000 filas
3. **Exploraci√≥n guiada**: Quality profiling autom√°tico
4. **Integraci√≥n fluida**: Conexi√≥n nativa con BigQuery

### Valor para Ingenier√≠a de Datos

- Herramienta esencial para **exploraci√≥n r√°pida** de datos
- Acelera **prototipos** de transformaciones
- Ideal para **equipos mixtos** (t√©cnicos y analistas)
- Excelente para **preparaci√≥n previa a ML**

### Comparaci√≥n con otras herramientas

| Herramienta | Ventaja | Desventaja |
|-------------|---------|------------|
| **SQL directo** | R√°pido para tareas simples | Menos visual |
| **Python ETL** | M√°s flexible | Menos accesible |
| **Dataflow manual** | M√°s control | M√°s complejo |
| **Dataprep** | Visual y colaborativo | Menos control fino |

---

## Conclusi√≥n

Se construy√≥ un pipeline completo de preparaci√≥n de datos:

1. ‚úÖ Configuraci√≥n de Cloud Dataprep
2. ‚úÖ Creaci√≥n de dataset en BigQuery
3. ‚úÖ Conexi√≥n y exploraci√≥n de datos
4. ‚úÖ Limpieza (filtrado, eliminaci√≥n de columnas)
5. ‚úÖ Enriquecimiento (ID √∫nico, etiquetas, normalizaci√≥n)
6. ‚úÖ Ejecuci√≥n en Dataflow
7. ‚úÖ Exportaci√≥n a BigQuery

**Takeaways clave:**

- La preparaci√≥n visual puede ser **tan poderosa como el c√≥digo**
- **Explorar antes de transformar** es esencial
- GCP ofrece **integraci√≥n nativa y fluida** entre servicios
- Las herramientas visuales **aumentan la colaboraci√≥n**
- Dataprep es ideal para **prototipado y limpieza intensiva**

---

## Pr√≥ximos Pasos

1. Usar datasets m√°s grandes para probar escalabilidad
2. Experimentar con joins y pivots complejos
3. Integrar Cloud Storage como origen adicional
4. Automatizar pipelines con Cloud Scheduler
5. Completar labs avanzados de Dataprep y Dataflow

---

## Referencias

- [Google Cloud Skills Boost](https://www.cloudskillsboost.google/)
- [Lab GSP430: Creating a Data Transformation Pipeline with Cloud Dataprep](https://www.cloudskillsboost.google/focuses/4415)
- [Cloud Dataprep Documentation](https://cloud.google.com/dataprep/docs)
- [Alteryx Designer Cloud](https://www.alteryx.com/products/alteryx-designer-cloud)
- [BigQuery Documentation](https://cloud.google.com/bigquery/docs)
- [Cloud Dataflow Documentation](https://cloud.google.com/dataflow/docs)
