---
title: "Pr√°ctica 5 ‚Äî An√°lisis de calidad de datos e imputaci√≥n en Ames Housing"
date: 2025-10-10
author: "Juan Paroli"
---

# üè† An√°lisis de calidad de datos e imputaci√≥n en Ames Housing

## Contexto

Este an√°lisis se centr√≥ en evaluar y tratar los problemas de **calidad de datos** del dataset *Ames Housing*, una base de datos ampliamente usada en aprendizaje autom√°tico para predecir precios de vivienda. El dataset contiene **2930 registros y 82 columnas**, con una mezcla de variables num√©ricas (‚âà 38) y categ√≥ricas (‚âà 43). Se abordaron los ejes clave de **valores faltantes**, **outliers** y **preprocesamiento reproducible**, generando visualizaciones y estrategias sistem√°ticas de imputaci√≥n y limpieza.

> El trabajo replica un flujo de preprocesamiento profesional, desde la exploraci√≥n inicial hasta la implementaci√≥n de pipelines reproducibles en `scikit-learn`.

Esta pr√°ctica fue desarrollada en un notebook de jupyter que puedes encontrar [aqu√≠](ames_housing.ipynb)

---

## Objetivos

- [x] Analizar la estructura del dataset e identificar patrones de valores faltantes.
- [x] Clasificar los tipos de *missing data* (MCAR, MAR, MNAR) presentes.
- [x] Implementar y comparar estrategias de imputaci√≥n simples y "smart".
- [x] Detectar y evaluar outliers mediante m√©todos IQR y Z-score.
- [x] Crear un pipeline reproducible de limpieza para modelos predictivos.

---

## Desarrollo

### 1. Exploraci√≥n inicial del dataset

**Setup**
- Dataset: **Ames Housing** (2930 registros y 82 columnas).
- Librer√≠as: `pandas`, `numpy`, `matplotlib`, `seaborn`, `scikit-learn`.
- An√°lisis de memoria: uso total de aproximadamente **6.9 MB**.

**Proceso**
- Carga y exploraci√≥n inicial del dataset.
- An√°lisis de estructura (tipos de datos, shape, memoria).
- Identificaci√≥n de variables con valores faltantes.

**Resultados clave**

- **29 columnas con valores faltantes** detectadas, con proporciones variables:
  - Variables con >90% de missing: `Pool QC`, `Misc Feature`, `Alley`.
  - Variables con missing moderado (5‚Äì10%): `Year Built`, `Garage Type`, `Garage Area`.
  - Variables num√©ricas cr√≠ticas como `SalePrice` (‚âà12% faltante) fueron parcialmente eliminadas para simular *MNAR* (faltantes no aleatorios).

Se elaboraron gr√°ficos de:
- **Top 10 columnas con mayor porcentaje de missing**, destacando `Pool QC` y `Misc Feature` (>95%).
- **Distribuci√≥n de missing por fila**, que mostr√≥ que la mayor√≠a de las filas tienen entre 0 y 5 valores faltantes, con pocos casos extremos.

Estas visualizaciones confirmaron que el problema no est√° concentrado en pocas observaciones, sino distribuido entre distintas columnas.

![](results/visualizaciones/top-10-porcentaje-missing.png)

![](results/visualizaciones/missing_patterns.png)

### 2. Clasificaci√≥n del missing data

Se introdujo missing sint√©tico para replicar escenarios reales de p√©rdida de informaci√≥n:

- **MCAR (Missing Completely At Random)** ‚Üí `Year Built`: los faltantes no dependen de otras variables ni del propio valor.
- **MAR (Missing At Random)** ‚Üí `Garage Area`: los faltantes dependen de una variable observable (`Garage Type`).
- **MNAR (Missing Not At Random)** ‚Üí `SalePrice`: los faltantes se asocian con precios altos, reflejando sesgo en la no respuesta.

Esta diferenciaci√≥n fue clave para definir **estrategias de imputaci√≥n adecuadas**.

### 3. An√°lisis de outliers

**Setup**
- M√©todos aplicados: **IQR (1.5√órango intercuart√≠lico)** y **Z-Score (¬±3 desviaciones est√°ndar)**.

**Proceso**
- Aplicaci√≥n de ambos m√©todos a todas las variables num√©ricas.
- Comparaci√≥n de resultados entre m√©todos.
- Visualizaci√≥n de outliers mediante boxplots.

**Resultados clave**

| M√©todo | Criterio | Contexto de uso |
|--------|-----------|----------------|
| IQR | 1.5√órango intercuart√≠lico | Distribuciones sesgadas o con colas pesadas |
| Z-Score | ¬±3 desviaciones est√°ndar | Distribuciones aproximadamente normales |

- En promedio, un **2.9% de los registros** fueron considerados outliers por IQR.
- Las variables con m√°s outliers fueron `Enclosed Porch`, `BsmtFin SF 2` y `Overall Cond`.
- La comparaci√≥n mostr√≥ que IQR detecta m√°s casos extremos que Z-Score, especialmente en variables sesgadas como `Lot Area` y `SalePrice`.

Se generaron boxplots con l√≠mites IQR y visualizaci√≥n logar√≠tmica para `Lot Area` y `SalePrice`, revelando alta asimetr√≠a.

![](results/visualizaciones/outliers_analysis.png)

### 4. Estrategias de imputaci√≥n

**Setup**
- Estrategias simples: media, mediana, moda.
- Estrategia "smart": reglas espec√≠ficas por tipo de variable y contexto.

**Proceso**
- Aplicaci√≥n de imputaci√≥n simple (media, mediana, moda).
- Implementaci√≥n de imputaci√≥n inteligente basada en agrupaciones.
- Comparaci√≥n de resultados.

**Resultados clave**

Se ensayaron tres estrategias simples (media, mediana, moda), las tres logrando **0 valores faltantes restantes**, pero con implicancias diferentes en la distribuci√≥n.

Posteriormente, se implement√≥ una **imputaci√≥n inteligente (smart)** con reglas espec√≠ficas por tipo de variable:
- `Year Built`: mediana por *Neighborhood* y *House Style* (MAR).
- `Garage Area`: imputaci√≥n condicional y creaci√≥n de *flag* binario para MNAR.
- `SalePrice`: mediana por *Neighborhood*.
- `Garage Type`: moda global.

Esta imputaci√≥n redujo la p√©rdida de informaci√≥n estructural, aunque persistieron **~15.591 valores imputados** en variables no cr√≠ticas.

### 5. Comparaci√≥n de distribuciones y correlaciones

**Proceso**
- Comparaci√≥n de histogramas y conteos categ√≥ricos entre datos originales e imputados.
- An√°lisis de correlaciones antes y despu√©s de la imputaci√≥n.

**Resultados clave**

Se compararon histogramas y conteos categ√≥ricos entre datos originales e imputados con la estrategia *SMART*. Las diferencias m√°s notorias se observaron en las variables num√©ricas sesgadas (`Lot Area`, `SalePrice`), aunque la estructura general se mantuvo.

![](results/visualizaciones/distribution_comparison.png)

El an√°lisis de correlaciones mostr√≥ **cambios menores (<0.2)** tras la imputaci√≥n, indicando que las relaciones entre variables clave (ej. `Overall Qual` ‚Üî `SalePrice`) se conservaron.

![](results/visualizaciones/correlation_comparison.png)

### 6. Pipeline reproducible

**Setup**
- Librer√≠as: `scikit-learn` (`Pipeline`, `ColumnTransformer`, `SimpleImputer`, `StandardScaler`, `OneHotEncoder`).

**Proceso**
- Creaci√≥n de pipeline modular que integra imputaci√≥n, escalamiento y codificaci√≥n.
- Implementaci√≥n de transformadores separados para variables num√©ricas y categ√≥ricas.

**Resultados clave**

Se desarroll√≥ un **pipeline modular** con `scikit-learn` que integra:
- Imputaci√≥n (`SimpleImputer`),
- Escalamiento (`StandardScaler`),
- Codificaci√≥n categ√≥rica (`OneHotEncoder`).

```python
def create_cleaning_pipeline():
    """Crear pipeline de limpieza reproducible"""

    # Definir columnas num√©ricas y categ√≥ricas
    numeric_features = ['SalePrice', 'Lot Area', 'Year Built', 'Garage Area']
    categorical_features = ['Neighborhood', 'House Style', 'Garage Type']

    # Transformadores
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),  # estrategia de imputaci√≥n
        ('scaler', StandardScaler())
    ])

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),  # estrategia de imputaci√≥n
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    # Combinar transformadores
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ]
    )

    return preprocessor
```

El resultado final fue una **matriz de 46 columnas transformadas**, lista para usarse en modelos predictivos sin intervenci√≥n manual.

---

## üìÅ Evidencias

### An√°lisis de valores faltantes

**Top 10 columnas con mayor porcentaje de missing**

![](results/visualizaciones/top-10-porcentaje-missing.png)

**Patrones de missing por fila**

![](results/visualizaciones/missing_patterns.png)

### An√°lisis de outliers

**Detecci√≥n de outliers con IQR y Z-Score**

![](results/visualizaciones/outliers_analysis.png)

### Comparaci√≥n de imputaci√≥n

**Comparaci√≥n de distribuciones antes y despu√©s de imputaci√≥n**

![](results/visualizaciones/distribution_comparison.png)

**Comparaci√≥n de correlaciones antes y despu√©s de imputaci√≥n**

![](results/visualizaciones/correlation_comparison.png)

### C√≥digo de ejemplo: Pipeline reproducible

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

# Crear pipeline de limpieza
preprocessor = create_cleaning_pipeline()

# Aplicar pipeline
X_transformed = preprocessor.fit_transform(X)
```

---

## üí° Reflexi√≥n

### Aprendizajes clave

- **El tratamiento del missing data no puede resolverse de forma gen√©rica**: cada variable requiere entender su origen, relaci√≥n con otras y posible sesgo. La clasificaci√≥n MCAR/MAR/MNAR es fundamental para elegir la estrategia correcta.
- **Las imputaciones basadas en agrupaciones** (por barrio o estilo de casa) preservan mejor la estructura interna de los datos que las imputaciones globales simples.
- **Los m√©todos robustos como IQR son preferibles** frente a Z-Score cuando las distribuciones son asim√©tricas, ya que no dependen de la normalidad de los datos.
- **Los pipelines reproducibles** son esenciales para mantener la consistencia y facilitar el mantenimiento del c√≥digo.

### Limitaciones y desaf√≠os

- **Algunas variables con >90% de missing** (ej. `Pool QC`) son pr√°cticamente inutilizables y deber√≠an considerarse para eliminaci√≥n o tratamiento especial.
- **La imputaci√≥n puede introducir sesgos** si no se realiza cuidadosamente, especialmente en variables MNAR.
- **El an√°lisis de outliers** requiere interpretaci√≥n contextual; no todos los outliers son errores, algunos pueden ser valores leg√≠timos pero extremos.

### Pr√≥ximos pasos

- Explorar t√©cnicas de imputaci√≥n m√°s avanzadas (KNN imputation, iterative imputation).
- Implementar validaci√≥n cruzada para evaluar el impacto de la imputaci√≥n en modelos predictivos.
- Desarrollar estrategias espec√≠ficas para variables con alta proporci√≥n de missing.

!!! warning "Atenci√≥n"
    La imputaci√≥n de datos faltantes puede introducir sesgos si no se realiza correctamente. Es crucial entender el mecanismo de missing (MCAR/MAR/MNAR) antes de elegir la estrategia de imputaci√≥n.

---

## üìö Referencias

- **Little, R. J. A., & Rubin, D. B. (2019)**. *Statistical Analysis with Missing Data*. Wiley.

- **Kaggle**: *Ames Housing Dataset*.
  [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)

- **van Buuren, S. (2018)**. *Flexible Imputation of Missing Data*. CRC Press.

- **Scikit-learn Documentation**: *Imputer & ColumnTransformer APIs*.
  [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)

- **Notebook completo**: [ames_housing.ipynb](ames_housing.ipynb)

---
