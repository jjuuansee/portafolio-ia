---
title: "Pr√°ctica 8 ‚Äî Feature Engineering para predecir precios de viviendas"
date: 2025-10-14
author: "Juan Paroli"
---

# üè† Construyendo valor con datos: Feature Engineering para predecir precios de viviendas

## Contexto

Este an√°lisis se centr√≥ en predecir precios de viviendas mediante t√©cnicas de **Feature Engineering**. Se trabaj√≥ primero con un **dataset sint√©tico de 1000 registros** con 10 variables iniciales, y luego se aplicaron las mismas t√©cnicas a un dataset real: **Ames Housing**. El objetivo fue encontrar la mejor relaci√≥n entre las columnas para predecir el precio, creando features derivadas que capturen patrones no obvios en los datos.

> **Objetivo**: demostrar c√≥mo el Feature Engineering puede mejorar la capacidad predictiva de los modelos al crear variables que capturan relaciones m√°s profundas entre las caracter√≠sticas de las viviendas.

Esta pr√°ctica fue desarrollada en un notebook de jupyter que puedes encontrar [aqu√≠](ocho.ipynb)

---

## Objetivos

- [x] Encontrar patrones y correlaciones entre variables.
- [x] Crear features derivadas para encontrar patrones no obvios en los datos.
- [x] Comparar el rendimiento de diferentes tipos de features (ratios, transformaciones, compuestas).
- [x] Evaluar features con datos sint√©ticos y reales (Ames Housing).
- [x] Predecir precios de viviendas con la mejor precisi√≥n.

---

## Desarrollo

### 1. Setup y creaci√≥n de dataset sint√©tico

**Setup**
- Dataset sint√©tico: **1000 registros** con **10 columnas** iniciales.
- Librer√≠as: `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`.
- Variables iniciales: `price`, `sqft`, `bedrooms`, `bathrooms`, `year_built`, `garage_spaces`, `lot_size`, `distance_to_city`, `school_rating`, `crime_rate`.

**Proceso**
- Generaci√≥n de dataset sint√©tico con distribuciones controladas.
- Definici√≥n de rangos para cada variable.
- Verificaci√≥n de ausencia de valores faltantes.

**Resultados clave**

```python
np.random.seed(42)
n_samples = 1000

data = {
    'price': np.random.normal(200000, 50000, n_samples),
    'sqft': np.random.normal(120, 30, n_samples),
    'bedrooms': np.random.choice([1, 2, 3, 4, 5], n_samples),
    'bathrooms': np.random.choice([1, 2, 3], n_samples),
    'year_built': np.random.choice(range(1980, 2024), n_samples),
    'garage_spaces': np.random.choice([0, 1, 2, 3], n_samples),
    'lot_size': np.random.normal(8000, 2000, n_samples),
    'distance_to_city': np.random.normal(15, 8, n_samples),
    'school_rating': np.random.uniform(1, 10, n_samples),
    'crime_rate': np.random.uniform(0, 100, n_samples)
}
```

Generar este dataset sint√©tico nos asegura de no tener datos nulos y nos permite controlar las relaciones entre variables.

### 2. Creaci√≥n de features derivadas

**Proceso**
- Creaci√≥n de features ratio que miden distintas relaciones.
- Aplicaci√≥n de transformaciones matem√°ticas.
- Construcci√≥n de features compuestas (scores).
- Creaci√≥n de variables temporales y categ√≥ricas.

**Resultados clave**

#### Features Ratio

- **Precio por pie cuadrado**: mide el valor relativo del espacio habitable.
  - Cu√°nto cuesta cada unidad de superficie construida.
  - Ratios altos ‚Üí zonas caras o propiedades premium.
  - Ratios bajos ‚Üí √°reas m√°s accesibles o construcciones menos valoradas.

- **Superficie por habitaci√≥n**: indica la amplitud promedio de los ambientes.
  - Cu√°nto espacio √∫til tiene cada dormitorio.
  - Ratios altos ‚Üí viviendas espaciosas (segmento medio-alto).
  - Ratios bajos ‚Üí unidades compactas o de densidad alta (segmento econ√≥mico).

- **Densidad de construcci√≥n**: mide la proporci√≥n del terreno ocupada por la edificaci√≥n.
  - Qu√© parte del lote est√° construida.
  - Ratios altos ‚Üí construcciones densas o urbanas.
  - Ratios bajos ‚Üí viviendas con jard√≠n o terrenos amplios (zonas suburbanas).

- **Ratio entre distancia a ciudad y rating de escuela**: eval√∫a el equilibrio entre accesibilidad urbana y calidad educativa.
  - Cu√°nto te alej√°s del centro por cada punto de calidad escolar.
  - Ratios bajos ‚Üí zonas bien ubicadas y con buenas escuelas.
  - Ratios altos ‚Üí barrios lejanos o con baja calidad educativa.

#### Variables Temporales y Categ√≥ricas

Tambi√©n capturamos relaciones temporales creando una variable de **antig√ºedad de la propiedad**, de la que se desprend√≠a una nueva variable (`age_category`) que asignaba a cada casa una entre 3 clasificaciones:
- Nuevo
- Moderno
- Antiguo

De esta nueva variable, construimos una √∫ltima variable booleana que asignaba `True` **si la propiedad era nueva**.

#### Transformaciones Matem√°ticas

Luego aplicamos transformaciones matem√°ticas a las variables del dataset:

- `log_price` ‚Äî **Logaritmo del precio**: transforma precios altamente dispersos en una escala m√°s homog√©nea. Permite analizar variaciones porcentuales en lugar de valores absolutos y reduce el impacto de valores extremos.

- `sqrt_sqft` ‚Äî **Ra√≠z cuadrada del tama√±o**: Suaviza la distribuci√≥n del tama√±o de las viviendas. √ötil cuando el tama√±o crece m√°s r√°pido que su impacto real en el precio, capturando rendimientos decrecientes del espacio.

- `sqft_squared` ‚Äî **Tama√±o al cuadrado**: Modela relaciones no lineales entre tama√±o y precio. Refleja casos donde un incremento en superficie genera un aumento acelerado en valor, t√≠pico de propiedades de lujo o alto est√°ndar.

#### Features Compuestas

Y por √∫ltimo concluimos con unas features compuestas que indicaban scores para las viviendas registradas:

- `luxury_score` ‚Äî **(precio + tama√±o + garage)**: √çndice sint√©tico de nivel de lujo o equipamiento.

- `location_score` ‚Äî **(rating escolar ‚àí distancia a ciudad)**: Mide la ventaja locacional de una propiedad.

**Total de features creadas**: **12 features derivadas** que ayudan a encontrar relaciones entre esos nuevos ratios y el precio.

![](results/distribucion_features_derivadas.png)

### 3. An√°lisis de importancia de features

**Setup**
- M√©todos aplicados:
  1. **Mutual Information (MI)**: mide la dependencia estad√≠stica entre cada variable y el objetivo, sin asumir linealidad.
  2. **Random Forest Feature Importance**: eval√∫a el impacto de cada feature en la reducci√≥n del error dentro de un modelo no lineal y de alta capacidad.

**Proceso**
- Aplicaci√≥n de ambos m√©todos a las 15 variables predictoras.
- Comparaci√≥n de resultados entre m√©todos.
- An√°lisis de diferencias y complementariedad.

**Resultados clave**

Se evalu√≥ la relevancia de **15 variables predictoras** respecto al precio de vivienda en el dataset.

![](results/importancia_de_features.png)

#### Mutual Information

- La **densidad de construcci√≥n** resulta ser el predictor m√°s informativo en sentido general, reflejando una relaci√≥n fuerte entre la proporci√≥n construida del lote y el valor final.
- **Cantidad de dormitorios** y **tama√±o transformado (ra√≠z cuadrada o cuadrado)** tambi√©n aportan informaci√≥n valiosa, lo que sugiere que la **escala del espacio habitable** sigue siendo el factor dominante.
- Variables como `distance_to_city`, `lot_size` o `garage_spaces` presentan informaci√≥n casi nula bajo este enfoque, indicando relaciones no evidentes o m√°s complejas (probablemente no lineales).

#### Random Forest Feature Importance

A diferencia de la MI, el Random Forest detect√≥ **patrones no lineales y combinaciones complejas**:

- El **√≠ndice de criminalidad** (`crime_rate`) fue la variable m√°s influyente, evidenciando un fuerte v√≠nculo entre seguridad y valor inmobiliario.
- Factores de **entorno y ubicaci√≥n** (`distance_to_city`, `school_rating`, `lot_size`) tambi√©n adquirieron gran relevancia, lo que concuerda con el comportamiento t√≠pico del mercado inmobiliario real.
- Variables derivadas como `city_school_ratio` y `construction_density` tambi√©n destacan, confirmando que las *features compuestas* capturan relaciones m√°s ricas entre ubicaci√≥n, servicios y estructura.

#### Comparaci√≥n de m√©todos

| Enfoque    | Qu√© captura mejor   | Limitaciones     |
| ---------- | ------------------- | ---------------- |
| **Mutual Information** | Relaciones estad√≠sticas directas y monot√≥nicas        | No detecta interacciones ni efectos combinados           |
| **Random Forest**      | Relaciones no lineales, interacciones entre variables | Menos interpretable y dependiente de los hiperpar√°metros |

En este caso, ambos m√©todos se complementan:
- MI enfatiza **estructura f√≠sica** del inmueble.
- Random Forest destaca **contexto ambiental y social**.

### 4. Investigaci√≥n libre: features creativas

**Proceso**
- Creaci√≥n de features adicionales libremente para seguir evaluando patrones.
- Evaluaci√≥n de correlaciones con el precio.
- An√°lisis de resultados vs expectativas.

**Resultados clave**

Se crearon otras features libremente para seguir evaluando los patrones:

- `space_efficiency`: mide proporci√≥n de superficie cubierta respecto al lote.
- `crowded_property`: densidad de dormitorios por m¬≤.
- `location_score`: √≠ndice de ubicaci√≥n combinando crimen, escuela y distancia.

Adem√°s se evalu√≥ interacciones como `price_age_interaction` y `distance_school_interaction`.

**An√°lisis de correlaciones**

Se esperaba que `space_efficiency`, `crowded_property` y `location_score` se correlacionaran positivamente con el precio.

- **`crowded_property`**: mantuvo una correlaci√≥n levemente positiva, significando que m√°s dormitorios por pie cuadrado aumenta el precio ‚úÖ
- **`space_efficiency`**: tuvo una correlaci√≥n levemente negativa, siendo contrario a lo esperado ‚ö†Ô∏è
- **`location_score`**: tuvo una correlaci√≥n levemente negativa, siendo contrario a lo esperado ‚ö†Ô∏è

**An√°lisis**

`location_score` es una feature creativa porque sintetiza variables externas en un √∫nico √≠ndice aunque los pesos usados no reflejaron bien la realidad.

**Futuras ideas de features**:
- Ajustar location_score con pesos calibrados (ej. regresi√≥n o PCA).
- Variables no lineales (cuadrados, logs) y normalizaci√≥n de distancias.
- Incorporar d√©cada de construcci√≥n o indicadores de accesibilidad.
- Ratios financieros como precio/ingreso promedio de la zona.

![](results/distribucion_features_libre.png)

### 5. Prueba con datos reales (Ames Housing)

**Setup**
- Dataset: **Ames Housing** (datos reales de viviendas).
- Variables: `SalePrice`, `GrLivArea`, `BedroomAbvGr`, `FullBath`, `YearBuilt`, `GarageCars`, `LotArea`, `Neighborhood`.
- Objetivo: Aplicar las mismas t√©cnicas de feature engineering a datos reales.

**Proceso**
- Creaci√≥n de features derivadas similares a las del dataset sint√©tico.
- An√°lisis de correlaciones con el precio.
- Comparaci√≥n de resultados entre datos sint√©ticos y reales.

**Resultados clave**

Con el objetivo de mejorar la capacidad predictiva del modelo, se generaron varias **features derivadas** a partir de las variables originales del dataset de Ames Housing:

- **`space_efficiency`**: relaci√≥n entre el √°rea habitable (`GrLivArea`) y el √°rea total del lote (`LotArea`). Mide el aprovechamiento del espacio disponible.
  - *Correlaci√≥n con el precio:* **0.875** ‚Üí las casas con mayor eficiencia espacial tienden a tener precios m√°s altos.

- **`property_age`**: antig√ºedad del inmueble calculada como `2025 - YearBuilt`.
  - *Correlaci√≥n con el precio:* **-0.822** ‚Üí a mayor antig√ºedad, menor precio, lo que refleja la depreciaci√≥n natural con el tiempo.

- **`age_size_interaction`**: producto entre la edad y la superficie (`HouseAge * GrLivArea`). Captura c√≥mo la combinaci√≥n de una casa grande y vieja puede afectar negativamente el valor.
  - *Correlaci√≥n con el precio:* **-0.437**, una relaci√≥n negativa moderada.

- **`bath_per_bedroom`**: proporci√≥n entre ba√±os completos y dormitorios. Indica el nivel de confort del hogar.
  - *Correlaci√≥n con el precio:* **0.658**, mostrando que las casas con m√°s ba√±os por dormitorio suelen ser m√°s costosas.

- **`garage_per_bedroom`**: cantidad de espacios de garaje por dormitorio, como indicador del equipamiento y comodidad.
  - *Correlaci√≥n con el precio:* **0.658**, similar a la anterior.

En conjunto, estas correlaciones muestran que las *features* dise√±adas tienen **fuerte relaci√≥n con el valor de venta**, especialmente las que reflejan **eficiencia espacial y antig√ºedad**. Adem√°s, las variables que describen **confort relativo** tambi√©n resultan relevantes para explicar el precio.

#### Preguntas de an√°lisis

**1. ¬øQu√© features funcionan mejor con datos reales?**

En los datos reales, las *features* que mejor funcionan son las que capturan **relaciones estructurales y contextuales** con sentido econ√≥mico:
- `space_efficiency` y `property_age` son las m√°s potentes, ya que combinan informaci√≥n de tama√±o, uso del espacio y depreciaci√≥n temporal.
- Las proporciones como `bath_per_bedroom` y `garage_per_bedroom` tambi√©n aportan valor al representar el confort del inmueble.

Estas variables reflejan comportamientos reales del mercado inmobiliario: el espacio bien aprovechado y la modernidad de la vivienda son factores clave en el precio.

**2. ¬øHay diferencias entre datos sint√©ticos y reales?**

S√≠, existen diferencias importantes:

| Aspecto                   | Datos Sint√©ticos                                                                             | Datos Reales                                                                                                      |
| ------------------------- | -------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |
| **Patrones**              | Se generan a partir de reglas fijas y aleatorias; las correlaciones pueden ser artificiales. | Reflejan decisiones humanas y del mercado, por lo que las relaciones son m√°s realistas pero tambi√©n m√°s ruidosas. |
| **Ruido y variabilidad**  | Controlados o inexistentes.                                                                  | Presentes; incluyen errores, valores at√≠picos y multicolinealidad.                                                |
| **Interpretabilidad**     | F√°cil, porque conocemos las reglas de generaci√≥n.                                            | Requiere an√°lisis y conocimiento del dominio.                                                                     |
| **Valor predictivo real** | Puede sobreestimar resultados (overfitting).                                                 | Permite generalizar mejor a nuevos datos.                                                                         |

**3. ¬øQu√© nuevas features podr√≠as crear con `Neighborhood`?**

La variable `Neighborhood` contiene informaci√≥n contextual de gran valor, ya que resume el entorno f√≠sico y socioecon√≥mico de la vivienda. A partir de ella, se pueden generar varias nuevas *features*:

1. **Estad√≠sticas de vecindario:**
   - Precio medio y desviaci√≥n est√°ndar por barrio:
     ```python
     df['neigh_price_mean'] = df.groupby('Neighborhood')['SalePrice'].transform('mean')
     df['neigh_price_std'] = df.groupby('Neighborhood')['SalePrice'].transform('std')
     df['price_vs_neigh'] = df['SalePrice'] / df['neigh_price_mean']
     ```
   - Permiten saber si una casa est√° por encima o por debajo del valor medio de su zona.

2. **Clasificaci√≥n socioecon√≥mica:**
   - Agrupar vecindarios seg√∫n su nivel de precio promedio (alto, medio, bajo).
   - Esto convierte la variable categ√≥rica en una **feature ordinal** interpretable.

---

## üìÅ Evidencias

### Distribuci√≥n de features derivadas

**Visualizaci√≥n de features creadas**

![](results/distribucion_features_derivadas.png)

### Importancia de features

**Comparaci√≥n entre Mutual Information y Random Forest**

![](results/importancia_de_features.png)

### Distribuci√≥n de features libres

**Features creativas y sus correlaciones**

![](results/distribucion_features_libre.png)

### C√≥digo de ejemplo: Creaci√≥n de features

```python
import pandas as pd
import numpy as np

# Features ratio
df['price_per_sqft'] = df['price'] / df['sqft']
df['sqft_per_bedroom'] = df['sqft'] / df['bedrooms']
df['construction_density'] = df['sqft'] / df['lot_size']

# Transformaciones matem√°ticas
df['log_price'] = np.log1p(df['price'])
df['sqrt_sqft'] = np.sqrt(df['sqft'])
df['sqft_squared'] = df['sqft'] ** 2

# Features compuestas
df['luxury_score'] = df['price'] + df['sqft'] + df['garage_spaces']
df['location_score'] = df['school_rating'] - df['distance_to_city']
```

---

## üí° Reflexi√≥n

### Aprendizajes clave

- **El Feature Engineering es fundamental para mejorar modelos**: Esta pr√°ctica demostr√≥ la importancia de analizar las relaciones entre las variables para que el modelo encuentre los patrones f√°cilmente. El Feature Engineering es necesario no solo para mejorar la performance del modelo sino tambi√©n para crear conocimiento del dominio.
- **Las features derivadas capturan relaciones no obvias**: Features como ratios, transformaciones matem√°ticas y compuestas pueden capturar relaciones que las variables originales no muestran directamente.
- **Los m√©todos de importancia de features se complementan**: Mutual Information y Random Forest Feature Importance capturan aspectos diferentes de las relaciones entre variables, siendo complementarios en el an√°lisis.
- **Los datos reales validan las features creadas**: Aplicar las mismas t√©cnicas a datos reales (Ames Housing) confirm√≥ que las features derivadas funcionan bien y tienen sentido en el contexto del mercado inmobiliario.

### Limitaciones y desaf√≠os

- **Features creativas pueden no funcionar como se espera**: Algunas features como `location_score` tuvieron correlaciones contrarias a lo esperado, demostrando que no todas las ideas de features son exitosas.
- **Los datos sint√©ticos tienen limitaciones**: Aunque √∫tiles para experimentar, los datos sint√©ticos pueden sobreestimar resultados y no reflejar completamente la complejidad de los datos reales.
- **El conocimiento del dominio es crucial**: Crear features efectivas requiere entender el dominio del problema y las relaciones reales entre variables.

### Pr√≥ximos pasos

- Explorar t√©cnicas m√°s avanzadas de feature engineering (polynomial features, feature interactions autom√°ticas).
- Implementar selecci√≥n autom√°tica de features para identificar las m√°s relevantes.
- Evaluar el impacto de las features en diferentes tipos de modelos (lineales, no lineales, ensemble).
- Incorporar t√©cnicas de deep learning para feature learning autom√°tico.

!!! warning "Atenci√≥n"
    Tambi√©n descubr√≠ la importancia de los datos reales en comparaci√≥n a los datasets sint√©ticos que generan datos con aleatoriedad. Los datos sint√©ticos son √∫tiles para experimentar, pero siempre deben validarse con datos reales antes de aplicarse en producci√≥n.

---

## üìö Referencias

- **Kaggle (2011)**. *Ames Housing Dataset*.
  [https://www.kaggle.com/datasets/prevek18/ames-housing-dataset](https://www.kaggle.com/datasets/prevek18/ames-housing-dataset)

- **Pandas Documentation**. *User Guide ‚Äî Working with Missing Data and Feature Creation*.
  [https://pandas.pydata.org/docs/user_guide/index.html](https://pandas.pydata.org/docs/user_guide/index.html)

- **Scikit-learn Documentation**. *Feature Engineering and Preprocessing Modules*.
  [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)

- **Kaggle Course**: *Feature Engineering*.
  [https://www.kaggle.com/learn/feature-engineering](https://www.kaggle.com/learn/feature-engineering)

- **Notebook completo**: [ocho.ipynb](ocho.ipynb)

---
