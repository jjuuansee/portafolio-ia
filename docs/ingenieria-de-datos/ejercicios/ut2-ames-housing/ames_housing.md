## ğŸ§­ **Resumen explicativo: PrÃ¡ctica 5 a 6 â€” Feature Scaling**

### ğŸ§© 1. Setup y carga del entorno

```python
import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
```

**PropÃ³sito:** preparar el entorno con librerÃ­as estÃ¡ndar de anÃ¡lisis y visualizaciÃ³n.

* `warnings.filterwarnings('ignore')` suprime mensajes innecesarios.
* `plt.style.use('seaborn-v0_8')` y `sns.set_palette("Set1")` configuran un estilo visual consistente.

âœ… *Punto clave:* establecer estilo y reproducibilidad antes de explorar.

---

### ğŸ  2. Carga del dataset Ames Housing y creaciÃ³n de *missing sintÃ©tico*

```python
df = pd.read_csv('AmesHousing.csv')
df.loc[missing_year, 'Year Built'] = np.nan
```

Se introducen tres tipos de valores faltantes controlados:

* **MCAR:** `Year Built` â†’ faltan completamente al azar.
* **MAR:** `Garage Area` â†’ faltantes dependen de `Garage Type`.
* **MNAR:** `SalePrice` â†’ faltantes dependen del propio valor.

ğŸ¯ *Objetivo:* practicar imputaciÃ³n diferenciando los mecanismos de â€œmissingnessâ€.

---

### ğŸ” 3. ExploraciÃ³n inicial

Uso de `df.info()`, `df.describe()`, `df.isnull().sum()`, etc.

**Se analiza:**

* Tipos de datos (int, float, object)
* Columnas con alto porcentaje de missing (`Alley`, `Pool QC`, etc.)
* Duplicados y memoria ocupada

ğŸ’¡ *Aprendizaje:* antes de imputar o escalar, es esencial conocer quÃ© tan limpio y equilibrado estÃ¡ el dataset.

---

### ğŸ“‰ 4. Patrones de missing data

Se genera un grÃ¡fico de barras y un histograma de filas con NaN.

**InterpretaciÃ³n:**

* 29 columnas con valores faltantes.
* Algunas con mÃ¡s del 90% â†’ probablemente descartables.

ğŸ“Š *Competencia tÃ©cnica:* aprender a visualizar la magnitud y distribuciÃ³n del problema de datos faltantes.

---

### ğŸ§© 5. ClasificaciÃ³n MCAR / MAR / MNAR

Mediante `groupby()` se comparan los patrones de missing con variables categÃ³ricas.

Ejemplo:

```python
df.groupby('Neighborhood')['Year Built'].apply(lambda x: x.isnull().sum())
```

**ConclusiÃ³n:**
Cada variable se clasifica segÃºn la dependencia observada.

---

### âš ï¸ 6. DetecciÃ³n de outliers

Se implementan dos mÃ©todos:

```python
def detect_outliers_iqr(df, col): ...
def detect_outliers_zscore(df, col): ...
```

**ComparaciÃ³n:**

* IQR â†’ robusto a distribuciones sesgadas.
* Z-score â†’ Ãºtil para distribuciones normales.

ğŸ“ˆ Se reportan conteos y lÃ­mites, mostrando que algunas variables (ej. `Enclosed Porch`, `Lot Area`) tienen altos porcentajes de outliers.

---

### ğŸ§± 7. ImputaciÃ³n de valores faltantes

Tres estrategias bÃ¡sicas (`mean`, `median`, `mode`) y una avanzada (`smart_imputation()`).

ğŸ”¹ *SimpleImputer* (numÃ©ricas: mediana / categÃ³ricas: moda)
ğŸ”¹ *Smart imputation* contextual: combina medianas por grupo y crea flags de missingness.

ğŸ“˜ *Mensaje clave:* la imputaciÃ³n debe ser informada, no ciega.

---

### ğŸ§¬ 8. Anti-leakage

El split correcto:

```python
X_train, X_valid, X_test = train_test_split(...)
numeric_imputer.fit(X_train)
```

ğŸ“› **Regla de oro:** â€œsplit antes de imputar o escalarâ€.

Evita que estadÃ­sticas del test â€œse filtrenâ€ al entrenamiento, inflando mÃ©tricas.

---

### ğŸ“Š 9. ComparaciÃ³n de distribuciones y correlaciones

Se grafican histogramas y heatmaps de correlaciones antes/despuÃ©s de la imputaciÃ³n.

**Objetivo:** comprobar que la imputaciÃ³n no altere excesivamente las relaciones entre variables.

---

### ğŸ”§ 10. CreaciÃ³n de *Pipeline* de limpieza

```python
preprocessor = ColumnTransformer([
  ('num', numeric_transformer, numeric_features),
  ('cat', categorical_transformer, categorical_features)
])
```

**Beneficio:** reproducibilidad y protecciÃ³n automÃ¡tica contra *data leakage*.

---

## ğŸ§  **TransiciÃ³n a PrÃ¡ctica 6: Feature Scaling**

### ğŸ§­ Paso 1â€“2: AnÃ¡lisis de escalas

Se inspeccionan rangos (`max - min`) y distribuciones.

Conclusiones:

* Variables con escalas mÃ¡s amplias: `PID`, `Lot Area`, `Misc Val`, `Total Bsmt SF`, `SalePrice`.
* Outliers extremos: `Lot Area` y `Mas Vnr Area`.

âš ï¸ *Estas diferencias afectan modelos basados en distancia (KNN, SVM).*

---

### âš—ï¸ Paso 3â€“4: PreparaciÃ³n y split

DefiniciÃ³n del target:

```python
target_col = "SalePrice"
```

SelecciÃ³n de features:

```python
["Lot Area", "Misc Val", "Total Bsmt SF"]
```

Y separaciÃ³n en train/test antes de escalar â†’ confirmando nuevamente que el problema de escalas persiste.

---

### ğŸ“ Paso 5: Experimento de escalado y outliers

ComparaciÃ³n entre:

* `StandardScaler`
* `MinMaxScaler`
* `RobustScaler`

ğŸ” Resultado:
No cambiÃ³ la detecciÃ³n de outliers (127 por IQR y 29 por Z-score), pero **RobustScaler** reduce la sensibilidad a ellos.

---

### ğŸ§ª Paso 6: InvestigaciÃ³n independiente â€” *PowerTransformer*

**Transformador elegido:** `PowerTransformer(method='yeo-johnson')`

PropÃ³sito:
Normalizar distribuciones sesgadas (reduce skewness y kurtosis).

**Resultados:**

| Variable      | Skew antes | Skew despuÃ©s |
| ------------- | ---------- | ------------ |
| SalePrice     | 1.44       | 0.075        |
| Lot Area      | 12.82      | 0.10         |
| Misc Val      | 22.0       | 5.05         |
| Total Bsmt SF | 1.16       | 0.11         |

âœ… *PowerTransformer* fue el Ãºnico que corrigiÃ³ la asimetrÃ­a, mientras que los scalers clÃ¡sicos solo escalan linealmente.

---

### ğŸ”¬ Paso 7: ComparaciÃ³n con scalers clÃ¡sicos

Resultados muestran:

* Standard / MinMax / Robust no cambian la forma.
* PowerTransformer mejora normalidad â†’ ideal para datos con colas largas o asimetrÃ­a fuerte.

---

### ğŸ§± Paso 8: Anti-leakage experimental

ComparaciÃ³n de tres mÃ©todos:

1. **Con leakage:** escalado antes del split
2. **Sin leakage:** split antes del escalado
3. **Pipeline:** anti-leakage automÃ¡tico

| MÃ©todo      | RÂ²     | MAE   |
| ----------- | ------ | ----- |
| Con leakage | 0.1846 | 36914 |
| Sin leakage | 0.1957 | 36442 |
| Pipeline    | 0.1957 | 36442 |

ğŸ“Š *ConclusiÃ³n:* el leakage puede parecer leve, pero invalida los resultados.

---

### ğŸ§© Paso 9: ValidaciÃ³n final

**Pipeline final:**

```python
Pipeline([
  ("scaler", PowerTransformer(method="yeo-johnson")),
  ("modelo", KNeighborsRegressor(n_neighbors=5))
])
```

**Cross-validation (CV=5):**

* RÂ² promedio â‰ˆ 0.12
* MAE â‰ˆ 34,000
  Vs baseline RÂ² â‰ˆ -0.02 (DummyRegressor)

âœ… *Pipeline + PowerTransformer* mejora rendimiento y mantiene buenas prÃ¡cticas.

---

### ğŸ’¡ ConclusiÃ³n general

* **Scaler ganador:** `PowerTransformer (Yeo-Johnson)`
* **Mejor prÃ¡ctica:** tratar outliers antes del escalado
* **Pipeline:** obligatorio para evitar *data leakage*
* **Regla de oro:** *Split â†’ Transform â†’ Train*
* **Checklist final:** revisa escalas, asimetrÃ­as, outliers y orden de operaciones.

---