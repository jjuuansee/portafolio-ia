---
title: "Pr√°ctica 6 ‚Äî Feature Scaling y Leakage en Ames Housing"
date: 2025-10-12
author: "Juan Paroli"
---

# üè† Feature Scaling y prevenci√≥n de Data Leakage: construyendo pipelines honestos en Ames Housing

## Contexto

Esta pr√°ctica extiende el trabajo previo de calidad de datos en [Ames Housing](../ut2-missing-data-detection/missing_data.md) para centrarse en **escalado de features**, **detecci√≥n/tratamiento de outliers** y **prevenci√≥n de data leakage**. El dataset **Ames Housing** contiene **2930 registros y 82 columnas**, con variables num√©ricas que presentan escalas muy dispares (desde cientos de millones hasta calificaciones 1-10). Adem√°s, incluye una **investigaci√≥n avanzada** sobre `PowerTransformer (Yeo‚ÄìJohnson)` y su comparaci√≥n con los scalers cl√°sicos.

> **Objetivo**: construir un **pipeline honesto (anti-leakage)**, seleccionar transformaciones adecuadas seg√∫n la **distribuci√≥n** de cada variable y demostrar su impacto en la **performance**.

Esta pr√°ctica fue desarrollada en un notebook de jupyter que puedes encontrar [aqu√≠](feature_scaling.ipynb)

---

## Objetivos

- [x] Diagnosticar **escalas dispares** y **outliers** que afecten algoritmos sensibles a distancia.
- [x] Comparar `StandardScaler`, `MinMaxScaler`, `RobustScaler` vs `PowerTransformer`.
- [x] Demostrar **data leakage** con tres estrategias (incorrecta/correcta/pipeline).
- [x] Validar con **cross-validation** y baseline para medir valor real.

---

## Desarrollo

### 1. Setup y preparaci√≥n de datos

**Setup**
- Dataset: **Ames Housing** (2930 filas, 82 columnas).
- *Missing* sint√©tico agregado en la [pr√°ctica previa](../ut2-missing-data-detection/missing_data.md) (MCAR/MAR/MNAR) y luego guardado en `df_imputed` (cero NaN restantes con reglas simples + "smart" por vecindario/estilo/garage).
- Librer√≠as: `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`.

**Proceso**
- Carga del dataset ya procesado con imputaci√≥n previa.
- Identificaci√≥n de variables num√©ricas con escalas dispares.
- An√°lisis de distribuciones y asimetr√≠a (skewness, kurtosis).

**Resultados clave**
- Variables con escalas muy diferentes detectadas: `PID`, `Lot Area`, `Mas Vnr Area`, `Year Built`, `Year Remod/Add`, `Order`.

### 2. An√°lisis de escalas dispares

Comenzamos analizando las escalas de las variables mediante un boxplot que aplica la transformaci√≥n *log1p*.

![](results/top5-escalas.png)

**An√°lisis de escalas**

Estas escalas se dan ya que estas variables tienen rangos enormes comparadas con otras:

- `PID`: va de **5.26e+08 a 1.00e+09** (escala de cientos de millones).
- `Lot Area`: va de **1300 a 215,245** (rango muy grande).
- `Mas Vnr Area`: de **0 a 1600**, mientras que muchas otras est√°n entre 1‚Äì10.
- `Year Built` y `Year Remod/Add`: rangos de **~100 a√±os (1872‚Äì2010)**, mucho mayores que escalas ordinales (1‚Äì10).
- `Order`: de **1 a 2930**, tambi√©n m√°s grande que calificaciones como Overall Qual (1‚Äì10).

### 3. Detecci√≥n de outliers

Para detectar los outliers se utilizaron dos enfoques complementarios:

| M√©todo            | Cu√°ndo usar                          |
| ----------------- | ------------------------------------ |
| **IQR (1.5√óIQR)** | Distribuciones sesgadas/colas largas |
| **Z-Score (¬±3œÉ)** | Distribuciones ~normales             |

**Resultados clave**

- Por IQR, `Lot Area` tuvo **127 outliers** (‚âà4.3%).
- Por Z-Score, `Lot Area` tuvo **29 outliers** (‚âà1.0%).
- En el barrido completo, el % promedio de outliers por IQR fue ‚âà **2.94%**; variables como `Enclosed Porch` y `Screen Porch` concentran muchos ceros (l√≠mites IQR en 0), elevando conteos.

**Efecto del escalado en la detecci√≥n de outliers**

Se prob√≥ el efecto del escalado en la detecci√≥n de outliers (con `Lot Area`):

| Escaler            | IQR (conteo) | Z-Score (conteo) |
| ------------------ | -----------: | ---------------: |
| **StandardScaler** |          127 |               29 |
| **MinMaxScaler**   |          127 |               29 |
| **RobustScaler**   |          127 |               29 |

**Hallazgo importante**: Entre las aplicaciones de `StandardScaler`, `MinMaxScaler` y `RobustScaler` no cambi√≥ la detecci√≥n de outliers ya que dieron la misma cantidad para los 3 m√©todos. El escalado **no afecta** la detecci√≥n de outliers cuando se aplica despu√©s de la detecci√≥n.

### 4. Comparaci√≥n de scalers cl√°sicos vs PowerTransformer

**PowerTransformer (Yeo‚ÄìJohnson)**

PowerTransformer corrige la asimetr√≠a de las distribuciones, siendo muy √∫til en el dataset actual que presenta distribuciones altamente sesgadas.

**Antes de transformar (skew | kurtosis)**

- `SalePrice`: **1.44 | 6.18**
- `Lot Area`: **12.82 | 265.02**
- `Misc Val`: **22.00 | 566.20**
- `Total Bsmt SF`: **1.16 | 9.14**

**Despu√©s con PowerTransformer (YJ, standardize=True)**

- `SalePrice__PT`: **0.08 | 2.21** ‚úÖ
- `Lot Area__PT`: **0.10 | 5.22** ‚úÖ
- `Misc Val__PT`: **5.05 | 23.53** ‚ö†Ô∏è (persiste asimetr√≠a por masa en 0)
- `Total Bsmt SF__PT`: **0.11 | 4.09** ‚úÖ

![](results/comparativa_skew.png)

**Resultados clave**: PowerTransformer logra **reducir significativamente la asimetr√≠a** en la mayor√≠a de las variables, especialmente en aquellas sin masa en cero. `Misc Val` presenta **masa en 0** por lo tanto persiste asimetr√≠a aun con Yeo-Johnson.

### 5. Demostraci√≥n de Data Leakage

Se compararon tres m√©todos con `KNeighborsRegressor (k=5)` para demostrar el problema de data leakage:

| M√©todo                                         | ¬øHay leakage? |         R¬≤ |  MAE (USD) |
| ---------------------------------------------- | ------------- | ---------: | ---------: |
| **1. Escalar todo y luego split**              | **S√≠** ‚ö†Ô∏è     |     0.1846 |     36,914 |
| **2. Split ‚Üí fit scaler en train ‚Üí transform** | No ‚úÖ         | **0.1957** | **36,443** |
| **3. Pipeline (Scaler‚ÜíModelo)**                | No ‚úÖ         | **0.1957** | **36,443** |

**An√°lisis**

- El m√©todo 1 "filtra" informaci√≥n del test al train (medias/desv√≠os), resultando en **m√©tricas optimistas pero inv√°lidas**.
- El **Pipeline** (3) automatiza el orden correcto y es el est√°ndar para **evitar errores** y usar **cross-validation** sin fugas.
- Los m√©todos 2 y 3 son equivalentes, pero el Pipeline es m√°s robusto y recomendado.

**Baseline (Dummy median, test)**: R¬≤ = **‚àí0.0443**; MAE ‚âà **39,416 USD**.

### 6. Validaci√≥n final con Cross-Validation

**Pipeline ganador:** `PowerTransformer(YJ) ‚Üí KNN (k=5)`

- R¬≤ (folds): `[0.0340, 0.1525, 0.1490, 0.0223, 0.2254]` ‚Üí **0.1166 ¬± 0.0773**
- MAE (folds): `[38,486; 33,607; 30,843; 34,818; 32,192]` ‚Üí **33,989 ¬± 2,615 USD**

**Baseline (Dummy median, CV=5)**

- R¬≤: **‚àí0.0248 ¬± 0.0248**
- MAE: **35,194 ¬± 2,027 USD**

**Resultados clave**: El pipeline con `PowerTransformer` brinda **R¬≤ positivo** sostenido y mejora el MAE vs. baseline (~**1,200 USD** menos en media), aunque el problema con s√≥lo 3 features sigue siendo desafiante (resultado *modesto pero real*).

---

## üìÅ Evidencias

### An√°lisis de escalas dispares

**Visualizaci√≥n de escalas (transformaci√≥n log1p)**

![](results/top5-escalas.png)

### Comparativa de transformaciones

**Reducci√≥n de asimetr√≠a con PowerTransformer**

![](results/comparativa_skew.png)

### C√≥digo de ejemplo: Pipeline anti-leakage

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PowerTransformer
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import cross_val_score

# Pipeline correcto (sin leakage)
pipeline = Pipeline([
    ('transformer', PowerTransformer(method='yeo-johnson', standardize=True)),
    ('model', KNeighborsRegressor(n_neighbors=5))
])

# Cross-validation honesta
scores = cross_val_score(pipeline, X_train, y_train, 
                         cv=5, scoring='r2')
print(f"R¬≤ medio: {scores.mean():.4f} ¬± {scores.std():.4f}")
```

---

## üí° Reflexi√≥n

### Aprendizajes clave

- **Detectar y tratar outliers antes del escalado** evita distorsionar medias/desv√≠os y rangos; luego aplicar escalado/transformaci√≥n.
- Los **scalers lineales** (Standard/MinMax/Robust) **no corrigen** asimetr√≠a; `PowerTransformer` s√≠, especialmente √∫til para distribuciones con colas largas.
- **Pipeline + CV** es **obligatorio** para evitar leakage y obtener m√©tricas honestas. El uso de pipelines automatiza el orden correcto y previene errores comunes.
- En variables como `Lot Area` o `SalePrice`, las **colas largas** justifican transformaciones no lineales como Yeo-Johnson.

### Limitaciones y desaf√≠os

- `Misc Val` presenta **masa en 0** por lo tanto persiste asimetr√≠a aun con Yeo-Johnson. Variables con alta concentraci√≥n de ceros requieren estrategias espec√≠ficas.
- El experimento de modelado us√≥ **pocas features** (demostraci√≥n). Un modelo final deber√≠a incorporar m√°s se√±ales (calidad, metros cubiertos, barrio, interacci√≥n, etc.).
- Las mejoras obtenidas, aunque reales, son modestas debido a la limitaci√≥n de features utilizadas.

### Pr√≥ximos pasos

- Incorporar m√°s variables relevantes al modelo (calidad, ubicaci√≥n, interacciones).
- Explorar otras transformaciones para variables con masa en cero.
- Implementar feature engineering adicional (ratios, interacciones, transformaciones temporales).

!!! warning "Atenci√≥n"
    El data leakage es un problema com√∫n y f√°cil de cometer. **Siempre** usar pipelines o asegurarse de que el escalado se ajuste solo con datos de entrenamiento antes de dividir train/test.

---

## üìö Referencias

- **Scikit-learn Documentation**: *Preprocessing (scalers, PowerTransformer), Pipeline, Model Selection*.
  [https://scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)

- **Box-Cox & Yeo‚ÄìJohnson**: Papers originales y notas de sklearn (para f√≥rmulas y supuestos).

- **Kaggle**: *Ames Housing Dataset*.
  [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)

- **Notebook completo**: [feature_scaling.ipynb](feature_scaling.ipynb)

---
