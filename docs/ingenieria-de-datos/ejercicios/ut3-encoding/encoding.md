---

title: "Encoding Avanzado"
date: 2025-10-22
author: "Juan Paroli"
categories: 
tags: 

---

# Target Encoding sobre sueldo de Adultos

## Contexto

En esta pr√°ctica se aborda como **predecir** si el ingreso anual de una persona supera 50k$ bas√°ndose en datos del censo. Se comparan distintas t√©cnicas de encoding para maximizar la precisi√≥n del modelo de clasificaci√≥n.

El **dataset** abarco un censo del 1994 de Estados Unidos con *32561* registros, y es un dataset cl√°sico del Machine Learningy benchmarking.


## Objetivos

- [x] Identificar relaciones de las variables con el target.
- [x] Comparar diferentes tecnicas de encoding.
- [x] Encontrar restricciones en aplicaciones como OneHotEncoding

---

## Desarrollo

### 1. Adult Data ‚Äî Censo estadounidense del 1994

**Setup**

- Fuente: UCI `adult` (32561 filas).
-  menores a 50k de ingresos: 24,720 (75.9%)
-  mayores a 50K de ingresos:  7,841 (24.1%)

**Se√±ales clave**
- No hay valores faltantes

---

### 2. An√°lisis de cardinalidad

Variables categ√≥ricas encontradas: 8

`workclass`, `education`, `marital-status`, `occupation`, `relationship`, `race`, `sex` y `native-country`

A cada variable categ√≥rica se le analiz√≥ cuantos valores √∫nicos toma para analizar la cardinalidad de cada variable. Si aplicamos OHE a estas columnas podemos tener problemas de dimensionalidad extremos.

**An√°lisis de cardinalidad**

Se clasific√≥ la cardinalidad de las features como:

- Baja <= 10
- 10 < Media <= 40
- Alta > 40  

Lo que clasific√≥ a las features de esta manera:

- `workclass`: 9 categor√≠as √∫nicas (BAJA)
- `education`: 16 categor√≠as √∫nicas (MEDIA)
- `marital-status`: 7 categor√≠as √∫nicas (BAJA)
- `occupation`: 15 categor√≠as √∫nicas (MEDIA)
- `relationship`: 6 categor√≠as √∫nicas (BAJA)
- `race`: 5 categor√≠as √∫nicas (BAJA)
- `sex`: 2 categor√≠as √∫nicas (BAJA)
- `native-country`: 42 categor√≠as √∫nicas (ALTA)


**Problema de dimensionalidad con OneHotEncoding**:

- workclass: 9 categor√≠as ‚Üí 8 columnas one-hot
- education: 16 categor√≠as ‚Üí 15 columnas one-hot
- marital-status: 7 categor√≠as ‚Üí 6 columnas one-hot
- occupation: 15 categor√≠as ‚Üí 14 columnas one-hot
- relationship: 6 categor√≠as ‚Üí 5 columnas one-hot
- race: 5 categor√≠as ‚Üí 4 columnas one-hot
- sex: 2 categor√≠as ‚Üí 1 columnas one-hot
- native-country: 42 categor√≠as ‚Üí 41 columnas one-hot

One-hot encoding **NO** es viable para variables de alta cardinalidad (como aparece en este dataset). Por lo tanto, necesitamos t√©cnicas alternativas:

- Label
- Target
- Hash
- Binary encoding

![](results/cardinal-analisis.png)

### 3. Label Encoding

Aplicamos Label Encoding para las columnas categ√≥ricas y luego evaluamos el performance al utilizar RandomForest

Label Encoding aplicado a 14 features. Los resultados obtenidos fueron:

- üìä Accuracy: 0.8632
- üìä AUC-ROC: 0.9101
- üìä F1-Score: 0.6931
- ‚è±Ô∏è Training time: 0.77s

### 4. OHE para features con baja cardinalidad

Tambien aplicamos OneHotEncoding √∫nicamente a las variables con baja cardinalidad. Por el problema de dimensionalidad que mencionamos de OHE. Y posteriormente entrenamos un Random Forest.

Los resultados obtenidos son levemente peores en comparaci√≥n a Label Encoding:


- üìä Accuracy: 0.8483
- üìä AUC-ROC: 0.8995
- üìä F1-Score: 0.6633
- ‚è±Ô∏è  Training time: 0.67s


### 5. Target Encoding con alta cardinalidad

Para la feature con alta cardinalidad `native-country` aplicamos Target Encoding. Con esta t√©cnica es importante el uso de cross-validation para prevenir DATA LEAKAGE.

Entrenamos un Random Forest nuevamente y estos fueron los resultados obtenidos:

- üìä Accuracy: 0.8092
- üìä AUC-ROC: 0.8318
- üìä F1-Score: 0.5658
- ‚è±Ô∏è  Training time: 1.63s

### 6. Analisis de Feature Importance

Luego de analizar las distintas tencicas de encoding con las features de baja y alta cardinalidad, aplicamos un Pipeline con branching de 3 ramas:

- Rama 1: One-Hot para baja cardinalidad (5 cols)
- Rama 2: Target Encoding para alta cardinalidad (1 cols)
- Rama 3: StandardScaler para num√©ricas (6 cols)

Este Pipeline generaba una cantidad de columnas nuevas considerable, sabiendo que part√≠amos de un todal de **12** Features originales. La transformaci√≥n gener√≥ un total de **31** features que se puede considerar de **dimensionalidad media**.

Entrenamos un Random Forest con estas Features y los resultados obtenidos fueron:

- üìä Accuracy: 0.8488
- üìä AUC-ROC: 0.9021
- üìä F1-Score: 0.6671
- ‚è±Ô∏è  Training time: 2.08s

Las columnas con m√°s importancia en el entrenamiento del Random Fores fueron:


üìä Analizando modelo con Pipeline Branching...
‚úÖ Features extra√≠das: 30
üîù Top Features m√°s importantes:

üìä Analizando modelo con Pipeline Branching...
‚úÖ Features extra√≠das: 30

üîù Top Features (feature importance)

| Rank | Feature                  | Importance |
|-----:|:-------------------------|-----------:|
| 1    | num__fnlwgt              | 0.223091   |
| 2    | num__age                 | 0.165969   |
| 3    | num__education-num       | 0.132941   |
| 4    | num__capital-gain        | 0.114665   |
| 5    | num__hours-per-week      | 0.092367   |

![](results/feature_importance.png)



Las **variables m√°s importantes** seg√∫n el an√°lisis de feature importance fueron principalmente **num√©ricas**, destac√°ndose:

- fnlwgt
- age
- education-num
- capital-gain
- hours-per-week.

Estas concentraron m√°s del **75% de la importancia total del modelo**, lo que muestra que las variables continuas aportan la mayor capacidad predictiva sobre los ingresos.

No hubo variables de alta cardinalidad (target encoded) relevantes en este caso, ya que el dataset Adult Income pr√°cticamente no conten√≠a variables de ese tipo (todas eran de baja o media cardinalidad).

El tipo de codificaci√≥n influye directamente en c√≥mo el modelo interpreta la informaci√≥n:

- One-Hot Encoding logr√≥ capturar bien la informaci√≥n de variables con baja cardinalidad, manteniendo buena interpretabilidad, pero **aumenta la dimensionalidad** (‚âà11√ó m√°s columnas).
- Label Encoding gener√≥ resultados s√≥lidos y simples, aunque puede introducir una relaci√≥n ordinal artificial entre categor√≠as que no la tienen.
- Target Encoding, aplicado a las de mayor cardinalidad, result√≥ √∫til pero menos destacable aqu√≠ por la ausencia de columnas con muchas categor√≠as.
- En t√©rminos de m√©tricas, las diferencias fueron peque√±as, aunque Label Encoding y Branched Pipeline mostraron un mejor balance entre rendimiento y eficiencia.

Las variables num√©ricas originales dominaron claramente al modelo, tanto en importancia total como promedio.

Esto sugiere que, en este dataset, la informaci√≥n estructural y cuantitativa (edad, a√±os de educaci√≥n, capital, horas trabajadas) es mucho m√°s informativa que las categor√≠as sociales o demogr√°ficas.

Las variables num√©ricas (age, education-num, capital-gain, hours-per-week) contin√∫an siendo las m√°s influyentes sobre la probabilidad de tener ingresos mayores a 50K.

SHAP tambi√©n muestra que las interacciones entre sex y marital-status influyen levemente, reflejando sesgos estructurales (por ejemplo, hombres casados tienden a tener mayor probabilidad de alto ingreso).

No aparecen nuevas features altamente relevantes que el Random Forest haya ignorado, lo cual indica consistencia entre ambas metodolog√≠as.

**Desde una perspectiva anal√≠tica y de negocio:**

- Los factores que m√°s predicen el ingreso son edad, nivel educativo, tipo de empleo y capital acumulado, lo que coincide con patrones socioecon√≥micos reales.
- Las categor√≠as relacionadas con el estado civil tambi√©n inciden, lo que puede reflejar correlaciones indirectas con estabilidad laboral o responsabilidades familiares.
- No se detectaron variables categ√≥ricas con alta cardinalidad que aporten valor adicional.
- Para aplicaciones pr√°cticas, esto implica que los modelos predictivos de ingresos pueden simplificarse priorizando las variables num√©ricas, reduciendo complejidad sin perder rendimiento.
- Adem√°s, es importante considerar posibles sesgos de g√©nero o de relaci√≥n familiar, ya que el modelo podr√≠a reproducir desigualdades presentes en los datos originales del censo.

---

## Reflexi√≥n

El experimento sobre **encoding avanzado** en el dataset *Adult Income* pone de manifiesto una verdad recurrente en proyectos reales de Machine Learning: **no siempre la complejidad en la representaci√≥n de los datos garantiza un mejor rendimiento del modelo**.

A pesar de probar estrategias de codificaci√≥n m√°s elaboradas ‚Äîcomo *Target Encoding* o *branching pipelines*‚Äî, los resultados muestran que las **variables num√©ricas** (edad, a√±os de educaci√≥n, capital y horas trabajadas) concentran la mayor parte del poder predictivo. Este hallazgo coincide con una caracter√≠stica estructural del problema: la desigualdad de ingresos responde en gran medida a factores cuantificables y menos a categor√≠as cualitativas.

La comparaci√≥n entre m√©todos de codificaci√≥n deja varias lecciones:

1. **Label Encoding** emerge como una opci√≥n eficiente y estable cuando el modelo no asume relaciones lineales estrictas (como los √°rboles de decisi√≥n). Su simplicidad evita la explosi√≥n dimensional y mantiene una excelente capacidad predictiva.
2. **One-Hot Encoding** es √∫til en variables de baja cardinalidad y mantiene interpretabilidad, aunque penaliza en escalabilidad y rendimiento cuando el n√∫mero de categor√≠as crece.
3. **Target Encoding**, si bien te√≥ricamente m√°s informativo para variables de alta cardinalidad, requiere una estructura de datos m√°s compleja y un manejo cuidadoso del *data leakage*. En este caso, la falta de columnas realmente ‚Äúaltas‚Äù en cardinalidad limit√≥ su aporte.
4. **Pipelines combinados (branching)** aportan modularidad y reproducibilidad, pero su ventaja pr√°ctica solo se justifica en escenarios con estructuras mixtas de datos o cardinalidades extremas.

Este estudio demuestra que la **selecci√≥n de t√©cnicas de encoding** debe guiarse por la naturaleza de los datos y no por la sofisticaci√≥n del m√©todo. En datasets con predominio de variables num√©ricas y categ√≥ricas de baja cardinalidad, una arquitectura simple ‚Äîcomo Label Encoding o una combinaci√≥n controlada con OHE‚Äî logra un balance √≥ptimo entre interpretabilidad, costo computacional y precisi√≥n.

> **La clave no est√° en usar el encoding m√°s avanzado, sino en usar el m√°s adecuado.**
> La explicabilidad, la alineaci√≥n con el contexto del negocio y la prevenci√≥n del sobreajuste son tan importantes como la m√©trica final de performance.

---


## üìö Referencias

- **Dua, D., & Graff, C. (2019).** *UCI Machine Learning Repository ‚Äî Adult Data Set.* University of California, Irvine.
  [https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)

- **Micci-Barreca, D. (2001).** *A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems.* SIGKDD Explorations, 3(1), 27‚Äì32.
 
- **Lema√Ætre, G., Nogueira, F., & Aridas, C. K. (2017).** *Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning.* Journal of Machine Learning Research, 18(17), 1‚Äì5.

- **Scikit-learn Developers (2024).** *User Guide: Encoding categorical features.*
  [https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)

- **Category Encoders (2017‚Äì2024).** *Official Documentation ‚Äî TargetEncoder, OrdinalEncoder, OneHotEncoder.*
  [https://contrib.scikit-learn.org/category_encoders/](https://contrib.scikit-learn.org/category_encoders/)

- **Lundberg, S. M., & Lee, S.-I. (2017).** *A Unified Approach to Interpreting Model Predictions (SHAP).* Advances in Neural Information Processing Systems (NeurIPS).
  [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)
  
- **Kaggle (2023).** *Adult Census Income Prediction ‚Äî Benchmark Notebook.*
  [https://www.kaggle.com/uciml/adult-census-income](https://www.kaggle.com/uciml/adult-census-income)

- [Notebook Completo](nueve.ipynb)

---
