{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fd0682c",
   "metadata": {},
   "source": [
    "# Tarea 15: Pipelines ETL, DataOps y OrquestaciÃ³n con Prefect\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c175349",
   "metadata": {},
   "source": [
    "## Parte 1 â€” InvestigaciÃ³n: Conceptos Fundamentales de Prefect (15 min)\n",
    "\n",
    "Antes de escribir cÃ³digo, investigamos la documentaciÃ³n oficial de Prefect y respondemos las siguientes preguntas. **Deben incluirse citas o referencias especÃ­ficas de la documentaciÃ³n.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c435",
   "metadata": {},
   "source": [
    "### 1.1 Tasks en Prefect\n",
    "\n",
    "**DocumentaciÃ³n oficial:** [Prefect Tasks](https://docs.prefect.io/latest/concepts/tasks/)\n",
    "\n",
    "#### 1. Â¿QuÃ© es una Task en Prefect?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Una **Task** en Prefect es una unidad de trabajo individual que representa una operaciÃ³n especÃ­fica dentro de un pipeline. SegÃºn la [documentaciÃ³n oficial de Prefect](https://docs.prefect.io/latest/concepts/tasks/), una task es \"a discrete piece of work that can be tracked and retried independently\". \n",
    "\n",
    "Las tasks son funciones Python decoradas con `@task` que encapsulan una lÃ³gica de trabajo especÃ­fica (por ejemplo, extraer datos, transformar un DataFrame, cargar en una base de datos). Son la unidad bÃ¡sica de ejecuciÃ³n en Prefect y pueden tener dependencias entre ellas, lo que permite que Prefect construya automÃ¡ticamente un DAG (grafo acÃ­clico dirigido) de ejecuciÃ³n.\n",
    "\n",
    "**CuÃ¡ndo usarla:** Se usa cuando necesitas dividir un flujo de trabajo en pasos discretos, reutilizables y rastreables. Cada task debe realizar una acciÃ³n especÃ­fica y bien definida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c41e5",
   "metadata": {},
   "source": [
    "#### 2. Â¿QuÃ© significa que las Tasks sean \"lazily evaluated\"?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "La evaluaciÃ³n diferida (\"lazy evaluation\") significa que las tasks **no se ejecutan inmediatamente** cuando se definen o cuando se llama a la funciÃ³n decorada. En su lugar, Prefect construye una representaciÃ³n del grafo de dependencias primero.\n",
    "\n",
    "Cuando llamas a una task dentro de un flow, Prefect no ejecuta el cÃ³digo de la task de inmediato. En lugar de eso, registra la llamada y las dependencias. La ejecuciÃ³n real ocurre cuando se ejecuta el flow completo, momento en el cual Prefect resuelve las dependencias y ejecuta las tasks en el orden correcto.\n",
    "\n",
    "Esto permite que Prefect optimice la ejecuciÃ³n, maneje dependencias complejas, y construya el DAG antes de ejecutar cualquier cosa. SegÃºn la [documentaciÃ³n de Prefect](https://docs.prefect.io/latest/concepts/flows/), esto es parte del concepto de \"imperative orchestration\" donde defines el flujo de manera imperativa pero Prefect lo ejecuta de manera declarativa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb7d4a",
   "metadata": {},
   "source": [
    "#### 3. Â¿QuÃ© son los Task States?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Los **Task States** representan el estado actual de una task durante su ciclo de vida. SegÃºn la [documentaciÃ³n de Prefect sobre States](https://docs.prefect.io/latest/concepts/states/), algunos estados posibles son:\n",
    "\n",
    "| Estado | Â¿CuÃ¡ndo ocurre? |\n",
    "|--------|----------------|\n",
    "| **PENDING** | La task estÃ¡ esperando ser ejecutada. Estado inicial cuando se crea la task y estÃ¡ en cola. |\n",
    "| **RUNNING** | La task estÃ¡ actualmente en ejecuciÃ³n. Ocurre cuando el cÃ³digo de la task estÃ¡ siendo procesado activamente. |\n",
    "| **COMPLETED** | La task se ejecutÃ³ exitosamente y retornÃ³ un resultado. Ocurre cuando la ejecuciÃ³n termina sin errores. |\n",
    "| **FAILED** | La task fallÃ³ durante su ejecuciÃ³n debido a una excepciÃ³n. Ocurre cuando se lanza una excepciÃ³n no capturada. |\n",
    "| **RETRYING** | La task estÃ¡ siendo reintentada despuÃ©s de un fallo. Ocurre cuando se configura `retries` y la task falla, antes del siguiente intento. |\n",
    "| **CANCELLED** | La task fue cancelada antes de completarse. Ocurre cuando el flow es cancelado o interrumpido externamente. |\n",
    "| **CRASHED** | La task fallÃ³ de manera inesperada o no manejada. Estado de fallo crÃ­tico cuando no hay manejo de errores. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc65b208",
   "metadata": {},
   "source": [
    "#### 4. Â¿QuÃ© parÃ¡metros importantes tiene el decorador `@task`?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "\n",
    "SegÃºn la [documentaciÃ³n de Prefect Tasks](https://docs.prefect.io/latest/api-ref/prefect/tasks/), algunos parÃ¡metros importantes son:\n",
    "\n",
    "| ParÃ¡metro | Â¿QuÃ© hace? | Ejemplo de uso |\n",
    "|-----------|------------|----------------|\n",
    "| **`retries`** | Define cuÃ¡ntas veces reintentar la task si falla. Por defecto es 0. | `@task(retries=3)` - La task intentarÃ¡ hasta 3 veces antes de fallar definitivamente. |\n",
    "| **`retry_delay_seconds`** | Tiempo de espera entre reintentos en segundos. Ãštil para tareas que pueden fallar temporalmente. | `@task(retries=2, retry_delay_seconds=5)` - Espera 5 segundos entre reintentos. |\n",
    "| **`timeout_seconds`** | Tiempo mÃ¡ximo de ejecuciÃ³n para la task. Si excede, se cancela automÃ¡ticamente. | `@task(timeout_seconds=300)` - La task debe completarse en 5 minutos o se cancela. |\n",
    "| **`cache_key_fn`** | FunciÃ³n personalizada para generar la clave de cachÃ©. Permite controlar cuÃ¡ndo se cachea un resultado. | `@task(cache_key_fn=lambda task, context: context['parameters']['date'])` - Cachea basado en un parÃ¡metro especÃ­fico. |\n",
    "| **`cache_expiration`** | DuraciÃ³n para la cual el resultado cacheado es vÃ¡lido. Puede ser un timedelta. | `@task(cache_expiration=timedelta(hours=1))` - El cache expira despuÃ©s de 1 hora. |\n",
    "| **`tags`** | Etiquetas para organizar y filtrar tasks. Ãštil para monitoreo y organizaciÃ³n. | `@task(tags=[\"extract\", \"production\"])` - Etiqueta la task para filtrado y organizaciÃ³n. |\n",
    "| **`log_prints`** | Si es True, captura los prints como logs de Prefect. Facilita el debugging. | `@task(log_prints=True)` - Los prints se registran automÃ¡ticamente en los logs de Prefect. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e97b0b",
   "metadata": {},
   "source": [
    "### 1.2 Flows en Prefect\n",
    "\n",
    "**DocumentaciÃ³n oficial:** [Prefect Flows](https://docs.prefect.io/latest/concepts/flows/)\n",
    "\n",
    "#### 1. Â¿CuÃ¡l es la diferencia entre un Flow y una Task? Â¿Por quÃ© necesitamos ambos?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "SegÃºn la [documentaciÃ³n de Prefect](https://docs.prefect.io/latest/concepts/flows/), un **Flow** es un contenedor que orquesta y coordina la ejecuciÃ³n de mÃºltiples Tasks. Mientras que una Task representa una unidad de trabajo individual, un Flow representa el flujo de trabajo completo que conecta mÃºltiples Tasks.\n",
    "\n",
    "**Diferencias clave:**\n",
    "- **Task**: Unidad bÃ¡sica de trabajo, realiza una acciÃ³n especÃ­fica\n",
    "- **Flow**: Orquesta mÃºltiples tasks, define las dependencias y el orden de ejecuciÃ³n\n",
    "\n",
    "**Â¿Por quÃ© necesitamos ambos?**\n",
    "- Las Tasks nos permiten dividir el trabajo en componentes reutilizables y rastreables\n",
    "- Los Flows nos permiten coordinar las Tasks, manejar dependencias automÃ¡ticamente, y proporcionar un contexto de ejecuciÃ³n unificado. Sin Flows, las Tasks serÃ­an funciones aisladas sin orquestaciÃ³n.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8343d64",
   "metadata": {},
   "source": [
    "#### 2. Â¿QuÃ© es un \"subflow\"? Â¿CuÃ¡ndo serÃ­a Ãºtil usar subflows?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Un **subflow** es un Flow que se puede llamar desde dentro de otro Flow. SegÃºn la [documentaciÃ³n de Prefect sobre subflows](https://docs.prefect.io/latest/concepts/flows/#composing-flows), cuando llamas a un flow decorado con `@flow` desde dentro de otro flow, automÃ¡ticamente se convierte en un subflow.\n",
    "\n",
    "**CuÃ¡ndo serÃ­a Ãºtil:**\n",
    "- **Modularidad**: Dividir un pipeline grande en mÃ³dulos mÃ¡s pequeÃ±os y manejables\n",
    "- **ReutilizaciÃ³n**: Reutilizar flujos comunes en mÃºltiples pipelines principales\n",
    "- **OrganizaciÃ³n**: Organizar lÃ³gicamente grupos relacionados de tasks\n",
    "- **Debugging**: Facilitar el debugging al aislar secciones del pipeline\n",
    "- **Testing**: Probar secciones especÃ­ficas del pipeline de manera independiente\n",
    "\n",
    "Por ejemplo, podrÃ­as tener un subflow `extract_and_validate()` que se use en mÃºltiples pipelines ETL diferentes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abf491",
   "metadata": {},
   "source": [
    "#### 3. Â¿CÃ³mo maneja Prefect las dependencias entre tasks? Expliquen el concepto de DAG implÃ­cito.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Prefect maneja las dependencias entre tasks de manera **automÃ¡tica e implÃ­cita** a travÃ©s de lo que se conoce como \"DAG implÃ­cito\". SegÃºn la [documentaciÃ³n de Prefect](https://docs.prefect.io/latest/concepts/flows/#task-dependencies), Prefect detecta automÃ¡ticamente las dependencias basÃ¡ndose en cÃ³mo se llaman las tasks dentro de un flow.\n",
    "\n",
    "**CÃ³mo funciona:**\n",
    "1. Cuando llamas a una task dentro de un flow y pasas el resultado de otra task como parÃ¡metro, Prefect automÃ¡ticamente detecta esa dependencia\n",
    "2. Prefect construye un DAG (grafo acÃ­clico dirigido) basÃ¡ndose en estas dependencias implÃ­citas\n",
    "3. Las tasks se ejecutan en el orden correcto segÃºn sus dependencias, no necesariamente en el orden en que aparecen en el cÃ³digo\n",
    "\n",
    "**Ejemplo:**\n",
    "```python\n",
    "@flow\n",
    "def my_flow():\n",
    "    data = extract_data()  # Task 1\n",
    "    transformed = transform_data(data)  # Task 2 depende de Task 1\n",
    "    load_data(transformed)  # Task 3 depende de Task 2\n",
    "```\n",
    "\n",
    "Prefect detecta automÃ¡ticamente que `transform_data` depende de `extract_data`, y `load_data` depende de `transform_data`, construyendo un DAG sin necesidad de especificarlo explÃ­citamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0081ff5",
   "metadata": {},
   "source": [
    "### 1.3 InvestigaciÃ³n avanzada: Results y Caching\n",
    "\n",
    "**DocumentaciÃ³n oficial:** [Prefect Results](https://docs.prefect.io/latest/concepts/results/) y [Caching](https://docs.prefect.io/latest/concepts/tasks/#caching)\n",
    "\n",
    "#### 1. Â¿QuÃ© es el \"result persistence\"? Â¿Por quÃ© es importante en pipelines de datos?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "El **result persistence** se refiere a la capacidad de Prefect de almacenar y recuperar los resultados de las tasks. SegÃºn la [documentaciÃ³n de Prefect sobre Results](https://docs.prefect.io/latest/concepts/results/), Prefect puede persistir los resultados de las tasks en diferentes backends (local, S3, GCS, etc.).\n",
    "\n",
    "**Â¿Por quÃ© es importante en pipelines de datos?**\n",
    "- **Resiliencia**: Si un flow falla a mitad de camino, no necesitas re-ejecutar todas las tasks desde el inicio\n",
    "- **Debugging**: Puedes inspeccionar los resultados intermedios para entender quÃ© saliÃ³ mal\n",
    "- **Reproducibilidad**: Puedes reproducir exactamente el mismo estado de ejecuciÃ³n\n",
    "- **Eficiencia**: En caso de fallo, solo necesitas re-ejecutar desde el punto de fallo\n",
    "- **AuditorÃ­a**: Permite rastrear y validar los resultados de cada etapa del pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08e11c4",
   "metadata": {},
   "source": [
    "#### 2. Â¿CÃ³mo funciona el caching en Prefect? Â¿QuÃ© parÃ¡metro usarÃ­an para cachear el resultado de una task?\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "El **caching** en Prefect permite que las tasks eviten la re-ejecuciÃ³n si ya se ejecutaron previamente con los mismos parÃ¡metros. SegÃºn la [documentaciÃ³n de Prefect sobre Caching](https://docs.prefect.io/latest/concepts/tasks/#caching), Prefect genera automÃ¡ticamente una clave de cachÃ© basÃ¡ndose en los parÃ¡metros de entrada de la task.\n",
    "\n",
    "**ParÃ¡metros para cachear:**\n",
    "- **`cache_key_fn`**: FunciÃ³n personalizada para generar la clave de cachÃ©\n",
    "- **`cache_expiration`**: DuraciÃ³n de validez del cachÃ© (ej: `timedelta(hours=1)`)\n",
    "- **`refresh_cache`**: Forzar la invalidaciÃ³n del cachÃ©\n",
    "\n",
    "**Ejemplo:**\n",
    "```python\n",
    "@task(cache_expiration=timedelta(hours=1))\n",
    "def extract_data(date: str):\n",
    "    # Esta task solo se ejecutarÃ¡ una vez por hora para la misma fecha\n",
    "    return fetch_data(date)\n",
    "```\n",
    "\n",
    "Si la misma task se llama con los mismos parÃ¡metros dentro de la ventana de expiraciÃ³n, Prefect retornarÃ¡ el resultado cacheado en lugar de re-ejecutar la task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e480026",
   "metadata": {},
   "source": [
    "#### 3. Â¿QuÃ© es una `cache_key_fn`? Den un ejemplo de cuÃ¡ndo la usarÃ­an.\n",
    "\n",
    "**Respuesta:**\n",
    "\n",
    "Una **`cache_key_fn`** es una funciÃ³n personalizada que se usa para generar la clave de cachÃ© de una task. SegÃºn la [documentaciÃ³n de Prefect](https://docs.prefect.io/latest/concepts/tasks/#cache-key-functions), permite controlar exactamente quÃ© factores determinan si una task debe ser re-ejecutada o usar el cachÃ©.\n",
    "\n",
    "**Ejemplo de uso:**\n",
    "\n",
    "```python\n",
    "@task(\n",
    "    cache_key_fn=lambda task, context: f\"{context['parameters']['date']}_{context['parameters']['region']}\"\n",
    ")\n",
    "def extract_regional_data(date: str, region: str, api_key: str):\n",
    "    # Esta task se cachea basÃ¡ndose en date y region, pero NO en api_key\n",
    "    return fetch_data(date, region, api_key)\n",
    "```\n",
    "\n",
    "**CuÃ¡ndo usarla:**\n",
    "- Cuando solo quieres cachear basÃ¡ndote en **algunos parÃ¡metros** (no todos)\n",
    "- Cuando necesitas incluir factores externos (como la hora del dÃ­a, estado de archivos) en la clave de cachÃ©\n",
    "- Cuando quieres invalidar el cachÃ© basÃ¡ndote en lÃ³gica de negocio compleja\n",
    "- Por ejemplo: cachear datos de ventas solo basÃ¡ndote en la fecha, ignorando otros parÃ¡metros como IDs de usuario que no afectan el resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59cbb2",
   "metadata": {},
   "source": [
    "## Parte 2 â€” DiseÃ±o Conceptual (5 min)\n",
    "\n",
    "Definimos un **escenario simple** para nuestro pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b198b7",
   "metadata": {},
   "source": [
    "### 2.1 Arquitectura del escenario\n",
    "\n",
    "**Escenario elegido**: Ventas de un e-commerce con datos de transacciones diarias\n",
    "\n",
    "| Rol | Â¿QuiÃ©n serÃ­a en nuestro escenario? |\n",
    "|-----|-----------------------------------|\n",
    "| **Business data owner** | Equipo de ventas/negocios que genera las transacciones diarias en la plataforma e-commerce |\n",
    "| **Data engineers** | Equipo de ingenierÃ­a de datos que construye y mantiene el pipeline ETL para procesar y cargar las ventas |\n",
    "| **Data consumers** | Analistas de negocio, cientÃ­ficos de datos y dashboards que consumen los datos procesados para anÃ¡lisis y reportes |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275e609",
   "metadata": {},
   "source": [
    "### 2.2 Tipo de pipeline\n",
    "\n",
    "* **Tipo elegido**: Batch\n",
    "* **JustificaciÃ³n**: Las ventas se procesan diariamente en lotes. No necesitamos procesamiento en tiempo real para este caso de uso inicial. El procesamiento batch es mÃ¡s eficiente para anÃ¡lisis agregados y permite procesar grandes volÃºmenes de datos de manera controlada. AdemÃ¡s, facilita la validaciÃ³n y el manejo de errores antes de cargar los datos procesados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b590aaa",
   "metadata": {},
   "source": [
    "## Parte 3 â€” ImplementaciÃ³n del Pipeline Base (20 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45948abd",
   "metadata": {},
   "source": [
    "### 3.1 Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d337495c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Entorno configurado correctamente\n",
      "ðŸ“… Fecha: 2025-12-08 17:19\n"
     ]
    }
   ],
   "source": [
    "# InstalaciÃ³n de Prefect\n",
    "# !pip install -q prefect pandas\n",
    "\n",
    "# Importar librerÃ­as\n",
    "from prefect import flow, task\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Entorno configurado correctamente\")\n",
    "print(f\"ðŸ“… Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7203fdf7",
   "metadata": {},
   "source": [
    "### 3.2 Implementar Tasks\n",
    "\n",
    "BasÃ¡ndose en lo que investigamos en la Parte 1, implementamos las tasks con los decoradores y parÃ¡metros correctos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e684b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TASK 1: EXTRACT ===\n",
    "# Decorador @task con parÃ¡metros Ãºtiles: tags para organizaciÃ³n y log_prints para capturar prints\n",
    "@task(tags=[\"extract\", \"data-source\"], log_prints=True)\n",
    "def extract_data():\n",
    "    \"\"\"\n",
    "    Extrae datos de la fuente.\n",
    "    Simula la extracciÃ³n de datos de ventas de un e-commerce.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_rows = 100\n",
    "\n",
    "    data = {\n",
    "        'fecha': pd.date_range(start='2024-01-01', periods=n_rows, freq='D'),\n",
    "        'producto': np.random.choice(['A', 'B', 'C', 'D'], n_rows),\n",
    "        'cantidad': np.random.randint(1, 50, n_rows),\n",
    "        'precio_unitario': np.random.uniform(10, 100, n_rows).round(2),\n",
    "        'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste'], n_rows)\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"ðŸ“¥ ExtraÃ­dos {len(df)} registros\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adf08548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TASK 2: TRANSFORM ===\n",
    "# Decorador @task con tags para organizaciÃ³n\n",
    "@task(tags=[\"transform\", \"data-processing\"], log_prints=True)\n",
    "def transform_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Aplica transformaciones a los datos.\n",
    "    Calcula totales, categorÃ­as de ticket size, y limpia los datos.\n",
    "    \"\"\"\n",
    "    # Calcular total\n",
    "    df['total'] = df['cantidad'] * df['precio_unitario']\n",
    "    \n",
    "    # Categorizar por ticket size\n",
    "    df['ticket_size'] = pd.cut(\n",
    "        df['total'],\n",
    "        bins=[0, 100, 500, 1000, float('inf')],\n",
    "        labels=['Bajo', 'Medio', 'Alto', 'Muy Alto']\n",
    "    )\n",
    "    \n",
    "    # Agregar mes y dÃ­a de la semana para anÃ¡lisis\n",
    "    df['mes'] = df['fecha'].dt.month\n",
    "    df['dia_semana'] = df['fecha'].dt.day_name()\n",
    "    \n",
    "    print(f\"ðŸ”„ Transformados {len(df)} registros\")\n",
    "    print(f\"   Total vendido: ${df['total'].sum():,.2f}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff65074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === TASK 3: LOAD ===\n",
    "# Decorador @task con tags y retries por si falla la escritura\n",
    "@task(tags=[\"load\", \"data-output\"], log_prints=True, retries=2, retry_delay_seconds=3)\n",
    "def load_data(df: pd.DataFrame, output_path: str = \"ventas_procesadas.csv\") -> str:\n",
    "    \"\"\"\n",
    "    Carga los datos transformados en el destino.\n",
    "    En producciÃ³n, esto podrÃ­a ser una base de datos, data warehouse, etc.\n",
    "    \"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"ðŸ’¾ Datos cargados en: {output_path}\")\n",
    "    print(f\"   Registros guardados: {len(df)}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaf8599",
   "metadata": {},
   "source": [
    "### 3.3 Implementar Flow\n",
    "\n",
    "Ahora creamos el flow principal que orquesta las tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9199225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FLOW PRINCIPAL ===\n",
    "@flow(name=\"ETL Pipeline Ventas\", log_prints=True)\n",
    "def etl_flow():\n",
    "    \"\"\"\n",
    "    Flow principal que orquesta el pipeline ETL completo.\n",
    "    Prefect detecta automÃ¡ticamente las dependencias entre tasks:\n",
    "    - transform_data depende de extract_data\n",
    "    - load_data depende de transform_data\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Iniciando pipeline ETL...\")\n",
    "    \n",
    "    # Paso 1: Extraer datos\n",
    "    df_raw = extract_data()\n",
    "    \n",
    "    # Paso 2: Transformar datos (depende de extract_data)\n",
    "    df_transformed = transform_data(df_raw)\n",
    "    \n",
    "    # Paso 3: Cargar datos (depende de transform_data)\n",
    "    output_file = load_data(df_transformed)\n",
    "    \n",
    "    print(f\"âœ… Pipeline completado. Archivo generado: {output_file}\")\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758dc13",
   "metadata": {},
   "source": [
    "### 3.4 Ejecutar el Flow\n",
    "\n",
    "Ejecutamos el flow para ver cÃ³mo funciona Prefect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70b6be3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:25.183 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'witty-platypus'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'witty-platypus'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'ETL Pipeline Ventas'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:25.183 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'witty-platypus'\u001b[0m - Beginning flow run\u001b[35m 'witty-platypus'\u001b[0m for flow\u001b[1;35m 'ETL Pipeline Ventas'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:25.189 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'witty-platypus'</span> - ðŸš€ Iniciando pipeline ETL...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:25.189 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'witty-platypus'\u001b[0m - ðŸš€ Iniciando pipeline ETL...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:26.301 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-f23' - ðŸ“¥ ExtraÃ­dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:26.301 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-f23' - ðŸ“¥ ExtraÃ­dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:27.578 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-f23' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:27.578 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-f23' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:28.829 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-87c' - ðŸ”„ Transformados 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:28.829 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-87c' - ðŸ”„ Transformados 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:28.836 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-87c' -    Total vendido: $136,630.33\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:28.836 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-87c' -    Total vendido: $136,630.33\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:30.236 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-87c' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:30.236 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-87c' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:31.797 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-cd4' - ðŸ’¾ Datos cargados en: ventas_procesadas.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:31.797 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-cd4' - ðŸ’¾ Datos cargados en: ventas_procesadas.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:31.810 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-cd4' -    Registros guardados: 100\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:31.810 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-cd4' -    Registros guardados: 100\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:33.019 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-cd4' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:33.019 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-cd4' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:33.028 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'witty-platypus'</span> - âœ… Pipeline completado. Archivo generado: ventas_procesadas.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:33.028 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'witty-platypus'\u001b[0m - âœ… Pipeline completado. Archivo generado: ventas_procesadas.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:33.108 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'witty-platypus'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:33.108 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'witty-platypus'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ Flow ejecutado exitosamente. Resultado: ventas_procesadas.csv\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el flow\n",
    "if __name__ == \"__main__\":\n",
    "    result = etl_flow()\n",
    "    print(f\"\\nðŸŽ‰ Flow ejecutado exitosamente. Resultado: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5efd0d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:34.702 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unnatural-toad'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unnatural-toad'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'ETL Pipeline Ventas'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:34.702 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unnatural-toad'\u001b[0m - Beginning flow run\u001b[35m 'unnatural-toad'\u001b[0m for flow\u001b[1;35m 'ETL Pipeline Ventas'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:34.709 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unnatural-toad'</span> - ðŸš€ Iniciando pipeline ETL...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:34.709 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unnatural-toad'\u001b[0m - ðŸš€ Iniciando pipeline ETL...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:35.995 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-b74' - ðŸ“¥ ExtraÃ­dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:35.995 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-b74' - ðŸ“¥ ExtraÃ­dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:37.117 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-b74' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:37.117 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-b74' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:38.185 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-27f' - ðŸ”„ Transformados 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:38.185 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-27f' - ðŸ”„ Transformados 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:38.192 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-27f' -    Total vendido: $136,630.33\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:38.192 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-27f' -    Total vendido: $136,630.33\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:39.283 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'transform_data-27f' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:39.283 | \u001b[36mINFO\u001b[0m    | Task run 'transform_data-27f' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:40.396 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-06f' - ðŸ’¾ Datos cargados en: ventas_procesadas.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:40.396 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-06f' - ðŸ’¾ Datos cargados en: ventas_procesadas.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:40.403 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-06f' -    Registros guardados: 100\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:40.403 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-06f' -    Registros guardados: 100\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:41.588 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'load_data-06f' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:41.588 | \u001b[36mINFO\u001b[0m    | Task run 'load_data-06f' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:41.595 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unnatural-toad'</span> - âœ… Pipeline completado. Archivo generado: ventas_procesadas.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:41.595 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unnatural-toad'\u001b[0m - âœ… Pipeline completado. Archivo generado: ventas_procesadas.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:19:41.671 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'unnatural-toad'</span> - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:19:41.671 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'unnatural-toad'\u001b[0m - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸŽ‰ Flow ejecutado exitosamente. Resultado: ventas_procesadas.csv\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar el flow (en notebook)\n",
    "result = etl_flow()\n",
    "print(f\"\\nðŸŽ‰ Flow ejecutado exitosamente. Resultado: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad4324",
   "metadata": {},
   "source": [
    "### 3.4 Preguntas de observaciÃ³n\n",
    "\n",
    "#### 1. Â¿QuÃ© observan en los logs de Prefect?\n",
    "**Respuesta:** Los logs muestran el estado de cada task (PENDING â†’ RUNNING â†’ COMPLETED), los mensajes de print capturados por `log_prints=True`, y un resumen del flujo de ejecuciÃ³n. Prefect proporciona informaciÃ³n detallada sobre el tiempo de ejecuciÃ³n de cada task y el flujo completo.\n",
    "\n",
    "#### 2. Â¿CÃ³mo se construyÃ³ el DAG?\n",
    "**Respuesta:** Prefect construyÃ³ el DAG automÃ¡ticamente basÃ¡ndose en las dependencias implÃ­citas detectadas cuando pasamos el resultado de una task como parÃ¡metro de otra. El DAG es: `extract_data` â†’ `transform_data` â†’ `load_data`.\n",
    "\n",
    "#### 3. Â¿QuÃ© pasarÃ­a si una task falla?\n",
    "**Respuesta:** Si una task falla, Prefect marca el estado como FAILED y detiene la ejecuciÃ³n del flow (a menos que configuremos manejo de errores). Las tasks dependientes no se ejecutarÃ¡n. Con `retries` configurado, Prefect reintentarÃ¡ la task antes de marcar como fallida.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc27ce",
   "metadata": {},
   "source": [
    "## Parte 4 â€” InvestigaciÃ³n: Funcionalidades Avanzadas (15 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4670a038",
   "metadata": {},
   "source": [
    "### 4.1 Retries y manejo de errores\n",
    "\n",
    "**InvestigaciÃ³n:** [Prefect Retries](https://docs.prefect.io/latest/concepts/tasks/#retries)\n",
    "\n",
    "**Respuestas:**\n",
    "\n",
    "1. **Â¿CÃ³mo funcionan los retries?** Prefect permite configurar reintentos automÃ¡ticos cuando una task falla. Se configuran con `@task(retries=N, retry_delay_seconds=X)` donde N es el nÃºmero de reintentos y X es el tiempo de espera entre intentos.\n",
    "\n",
    "2. **Â¿CuÃ¡ndo usar retries?** Ãštil para operaciones que pueden fallar temporalmente (APIs, conexiones de red, operaciones de I/O). No es recomendable para errores de lÃ³gica que siempre fallarÃ¡n.\n",
    "\n",
    "3. **Ya lo implementamos:** En la task `load_data()` configuramos `retries=2, retry_delay_seconds=3` para manejar posibles fallos en la escritura del archivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cf2db",
   "metadata": {},
   "source": [
    "### 4.2 Caching de resultados\n",
    "\n",
    "**InvestigaciÃ³n:** [Prefect Caching](https://docs.prefect.io/latest/concepts/tasks/#caching)\n",
    "\n",
    "**Respuestas:**\n",
    "\n",
    "1. **Â¿CÃ³mo funciona el caching?** Prefect genera automÃ¡ticamente una clave de cachÃ© basada en los parÃ¡metros de entrada. Si la misma task se ejecuta con los mismos parÃ¡metros, retorna el resultado cacheado en lugar de re-ejecutar.\n",
    "\n",
    "2. **ParÃ¡metros clave:** `cache_expiration` (timedelta) y `cache_key_fn` (funciÃ³n personalizada).\n",
    "\n",
    "3. **CuÃ¡ndo usar:** Para tasks costosas que pueden reutilizar resultados (extracciones de APIs, procesamiento pesado) cuando los parÃ¡metros no cambian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176f6942",
   "metadata": {},
   "source": [
    "### 4.3 Logging personalizado\n",
    "\n",
    "**InvestigaciÃ³n:** [Prefect Logging](https://docs.prefect.io/latest/concepts/logs/)\n",
    "\n",
    "**Respuestas:**\n",
    "\n",
    "1. **Â¿CÃ³mo usar logging?** Se puede usar `get_run_logger()` dentro de una task para obtener un logger estructurado, o configurar `log_prints=True` para capturar automÃ¡ticamente los prints.\n",
    "\n",
    "2. **Ya lo implementamos:** Usamos `log_prints=True` en todas nuestras tasks para que los prints se registren como logs estructurados de Prefect.\n",
    "\n",
    "3. **Ventajas:** Logs centralizados, niveles de log (INFO, WARNING, ERROR), y integraciÃ³n con la UI de Prefect para debugging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb51da1",
   "metadata": {},
   "source": [
    "### 4.4 Concurrencia y paralelismo\n",
    "\n",
    "**InvestigaciÃ³n:** [Prefect Task Runners](https://docs.prefect.io/latest/concepts/task-runners/)\n",
    "\n",
    "**Respuestas:**\n",
    "\n",
    "1. **Â¿CÃ³mo funciona?** Prefect soporta ejecuciÃ³n concurrente usando `ConcurrentTaskRunner()` como parÃ¡metro del flow. Las tasks independientes pueden ejecutarse en paralelo.\n",
    "\n",
    "2. **CuÃ¡ndo usar:** Cuando tienes mÃºltiples tasks que no dependen una de otra y quieres reducir el tiempo total de ejecuciÃ³n.\n",
    "\n",
    "3. **Ejemplo:** Si procesamos datos por regiÃ³n, podemos usar `futures = [process_region.submit(r) for r in regions]` para ejecutar en paralelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e65b93",
   "metadata": {},
   "source": [
    "## Parte 5 â€” InvestigaciÃ³n: Deployments y Scheduling (10 min)\n",
    "\n",
    "**DocumentaciÃ³n:** [Deployments](https://docs.prefect.io/latest/concepts/deployments/) y [Schedules](https://docs.prefect.io/latest/concepts/schedules/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217490e",
   "metadata": {},
   "source": [
    "### 5.1 Conceptos de Deployment\n",
    "\n",
    "**Respuestas basadas en la documentaciÃ³n:**\n",
    "\n",
    "1. **Â¿QuÃ© es un Deployment en Prefect?** Un Deployment es una configuraciÃ³n que permite ejecutar un Flow de manera programada o bajo demanda. SegÃºn la [documentaciÃ³n](https://docs.prefect.io/latest/concepts/deployments/), un Deployment conecta un Flow con una configuraciÃ³n de ejecuciÃ³n especÃ­fica (scheduling, work pool, parÃ¡metros). La diferencia con un Flow es que un Flow es el cÃ³digo, mientras que un Deployment es la \"instalaciÃ³n\" del Flow en Prefect Cloud/Server para ejecutarlo.\n",
    "\n",
    "2. **Â¿QuÃ© es un Work Pool?** Un Work Pool es un grupo de workers que pueden ejecutar flows. SegÃºn la [documentaciÃ³n](https://docs.prefect.io/latest/concepts/work-pools/), permite organizar dÃ³nde y cÃ³mo se ejecutan los flows (local, servidor, cloud). Es una abstracciÃ³n para manejar la infraestructura de ejecuciÃ³n.\n",
    "\n",
    "3. **Â¿QuÃ© es un Worker?** Un Worker es un proceso que ejecuta flows desde un Work Pool. Los Workers se conectan a un Work Pool y \"toman\" trabajos (flows) para ejecutarlos. La relaciÃ³n es: Deployment â†’ Work Pool â†’ Worker â†’ EjecuciÃ³n del Flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff5336d",
   "metadata": {},
   "source": [
    "### 5.2 Scheduling\n",
    "\n",
    "**Tipos de schedules soportados por Prefect:**\n",
    "\n",
    "| Tipo de Schedule | DescripciÃ³n | Ejemplo |\n",
    "|-----------------|-------------|---------|\n",
    "| **CronSchedule** | Usa sintaxis cron para definir horarios recurrentes | `cron=\"0 6 * * *\"` - Todos los dÃ­as a las 6 AM |\n",
    "| **IntervalSchedule** | Ejecuta a intervalos fijos de tiempo | `interval=timedelta(hours=1)` - Cada hora |\n",
    "| **RRuleSchedule** | Usa reglas RFC 5545 (iCalendar) para horarios complejos | Ãštil para horarios de negocio, excluir fines de semana |\n",
    "| **Manual** | Sin schedule, solo ejecuciÃ³n manual | Para ejecuciÃ³n bajo demanda |\n",
    "\n",
    "**1. Â¿CÃ³mo expresarÃ­an \"ejecutar todos los dÃ­as a las 6 AM\" en cron?**\n",
    "**Respuesta:** `\"0 6 * * *\"` - El formato cron es: minuto hora dÃ­a_mes mes dÃ­a_semana\n",
    "\n",
    "**2. Â¿QuÃ© es `RRuleSchedule`?** \n",
    "**Respuesta:** RRuleSchedule permite definir horarios complejos usando reglas RFC 5545, como \"cada lunes y miÃ©rcoles a las 9 AM, excepto feriados\" o \"Ãºltimo dÃ­a del mes\". Es mÃ¡s flexible que cron para casos de negocio complejos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499758f5",
   "metadata": {},
   "source": [
    "### 5.3 Crear un Deployment (conceptual)\n",
    "\n",
    "BasÃ¡ndose en la documentaciÃ³n, cÃ³digo para crear un deployment del flow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee7115ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CÃ³digo conceptual de deployment - Ver comentarios arriba para uso en producciÃ³n\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CÃ“DIGO CONCEPTUAL - NO EJECUTAR EN NOTEBOOK\n",
    "# ============================================================\n",
    "# Este cÃ³digo estÃ¡ diseÃ±ado para ejecutarse como un SCRIPT (.py),\n",
    "# no en un Jupyter notebook. serve() inicia un servidor que corre\n",
    "# indefinidamente esperando ejecuciones programadas.\n",
    "#\n",
    "# Para usar esto en producciÃ³n, guardar en un archivo .py y ejecutar:\n",
    "#   python mi_deployment.py\n",
    "# ============================================================\n",
    "\n",
    "# from prefect import flow\n",
    "#\n",
    "# # NOTA: En Prefect 2/3 no es necesario importar CronSchedule.\n",
    "# # El schedule se pasa directamente como string al parÃ¡metro 'cron'.\n",
    "#\n",
    "# # OpciÃ³n 1: Usando serve() - mÃ¡s simple para desarrollo\n",
    "# if __name__ == \"__main__\":\n",
    "#     etl_flow.serve(\n",
    "#         name=\"etl-ventas-daily\",  # nombre del deployment\n",
    "#         cron=\"0 6 * * *\",  # schedule: todos los dÃ­as a las 6 AM\n",
    "#         tags=[\"production\", \"etl\", \"ventas\"],  # tags para organizaciÃ³n\n",
    "#     )\n",
    "#\n",
    "# # OpciÃ³n 2: Usando deploy() - mÃ¡s control para producciÃ³n\n",
    "# # etl_flow.deploy(\n",
    "# #     name=\"etl-ventas-daily\",\n",
    "# #     work_pool_name=\"default\",  # o un work pool especÃ­fico\n",
    "# #     cron=\"0 6 * * *\",\n",
    "# #     tags=[\"production\", \"etl\"],\n",
    "# # )\n",
    "\n",
    "print(\"âœ… CÃ³digo conceptual de deployment - Ver comentarios arriba para uso en producciÃ³n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a751c5c7",
   "metadata": {},
   "source": [
    "## Parte 6 â€” ExtensiÃ³n DataOps (15 min)\n",
    "\n",
    "Elegimos implementar la **OpciÃ³n A â€” ValidaciÃ³n con logging estructurado**, ya que es fundamental para la calidad de datos en pipelines ETL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4172317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPCIÃ“N A: VALIDACIÃ“N CON LOGGING ESTRUCTURADO ===\n",
    "from prefect import get_run_logger\n",
    "\n",
    "@task(retries=1, retry_delay_seconds=2, tags=[\"validation\", \"data-quality\"], log_prints=True)\n",
    "def validate_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Valida la calidad de los datos usando logging estructurado de Prefect.\n",
    "    Esta task valida que los datos cumplan con las expectativas antes de continuar.\n",
    "    \n",
    "    Basado en: https://docs.prefect.io/latest/concepts/logs/\n",
    "    \"\"\"\n",
    "    logger = get_run_logger()  # Obtiene el logger estructurado de Prefect\n",
    "    errors = []\n",
    "\n",
    "    logger.info(\"Iniciando validaciÃ³n de datos\")\n",
    "    logger.info(f\"DataFrame recibido con {len(df)} registros y {len(df.columns)} columnas\")\n",
    "\n",
    "    # ValidaciÃ³n 1: DataFrame no vacÃ­o\n",
    "    if len(df) <= 0:\n",
    "        logger.error(\"DataFrame vacÃ­o detectado - No se pueden procesar datos vacÃ­os\")\n",
    "        errors.append(\"DataFrame vacÃ­o\")\n",
    "    else:\n",
    "        logger.info(f\"âœ… ValidaciÃ³n de cantidad de registros: OK ({len(df)} registros)\")\n",
    "\n",
    "    # ValidaciÃ³n 2: Valores nulos\n",
    "    null_counts = df.isnull().sum()\n",
    "    if null_counts.sum() > 0:\n",
    "        logger.warning(f\"Valores nulos encontrados: {null_counts[null_counts > 0].to_dict()}\")\n",
    "        # No agregamos a errors si hay nulos, solo lo registramos como warning\n",
    "        # En producciÃ³n, podrÃ­as decidir si esto es crÃ­tico o no\n",
    "    else:\n",
    "        logger.info(\"âœ… ValidaciÃ³n de valores nulos: OK (sin nulos)\")\n",
    "\n",
    "    # ValidaciÃ³n 3: Columnas requeridas\n",
    "    required_columns = ['fecha', 'producto', 'cantidad', 'precio_unitario', 'total']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        logger.error(f\"Columnas requeridas faltantes: {missing_columns}\")\n",
    "        errors.append(f\"Columnas faltantes: {missing_columns}\")\n",
    "    else:\n",
    "        logger.info(f\"âœ… ValidaciÃ³n de columnas requeridas: OK\")\n",
    "\n",
    "    # ValidaciÃ³n 4: Tipos de datos bÃ¡sicos\n",
    "    if 'total' in df.columns:\n",
    "        if df['total'].dtype not in [float, 'float64', 'float32', int, 'int64', 'int32']:\n",
    "            logger.error(f\"Tipo de dato incorrecto para 'total': {df['total'].dtype}\")\n",
    "            errors.append(\"Tipo de dato incorrecto en columna 'total'\")\n",
    "        else:\n",
    "            logger.info(\"âœ… ValidaciÃ³n de tipos de datos: OK\")\n",
    "\n",
    "    # ValidaciÃ³n 5: Valores negativos en campos que no deberÃ­an tenerlos\n",
    "    if 'cantidad' in df.columns:\n",
    "        negative_qty = (df['cantidad'] < 0).sum()\n",
    "        if negative_qty > 0:\n",
    "            logger.warning(f\"Se encontraron {negative_qty} registros con cantidad negativa\")\n",
    "            # PodrÃ­as decidir si esto es un error crÃ­tico o solo un warning\n",
    "\n",
    "    if errors:\n",
    "        logger.error(f\"ValidaciÃ³n fallida con {len(errors)} error(es) crÃ­tico(s)\")\n",
    "        raise ValueError(f\"ValidaciÃ³n fallida: {errors}\")\n",
    "\n",
    "    logger.info(\"âœ… ValidaciÃ³n exitosa - Todos los checks pasaron\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad913c9",
   "metadata": {},
   "source": [
    "Ahora actualizamos el flow para incluir la validaciÃ³n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e15a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === FLOW ACTUALIZADO CON VALIDACIÃ“N ===\n",
    "@flow(name=\"ETL Pipeline Ventas con ValidaciÃ³n\", log_prints=True)\n",
    "def etl_flow_with_validation():\n",
    "    \"\"\"\n",
    "    Flow principal que orquesta el pipeline ETL completo con validaciÃ³n de calidad.\n",
    "    Incluye validaciÃ³n entre extract y transform para asegurar calidad de datos.\n",
    "    \"\"\"\n",
    "    print(\"ðŸš€ Iniciando pipeline ETL con validaciÃ³n...\")\n",
    "    \n",
    "    # Paso 1: Extraer datos\n",
    "    df_raw = extract_data()\n",
    "    \n",
    "    # Paso 2: Validar datos (EXTENSIÃ“N DATAOPS)\n",
    "    # Esta validaciÃ³n asegura que los datos cumplen con las expectativas antes de transformar\n",
    "    df_validated = validate_data(df_raw)\n",
    "    \n",
    "    # Paso 3: Transformar datos (solo si la validaciÃ³n pasa)\n",
    "    df_transformed = transform_data(df_validated)\n",
    "    \n",
    "    # Paso 4: Cargar datos\n",
    "    output_file = load_data(df_transformed)\n",
    "    \n",
    "    print(f\"âœ… Pipeline completado con validaciÃ³n. Archivo generado: {output_file}\")\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69110881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:44.554 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'copper-pudu'</span> - Beginning flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'copper-pudu'</span> for flow<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> 'ETL Pipeline Ventas con ValidaciÃ³n'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:44.554 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'copper-pudu'\u001b[0m - Beginning flow run\u001b[35m 'copper-pudu'\u001b[0m for flow\u001b[1;35m 'ETL Pipeline Ventas con ValidaciÃ³n'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:44.559 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'copper-pudu'</span> - ðŸš€ Iniciando pipeline ETL con validaciÃ³n...\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:44.559 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'copper-pudu'\u001b[0m - ðŸš€ Iniciando pipeline ETL con validaciÃ³n...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:45.672 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-92b' - ðŸ“¥ ExtraÃ­dos 100 registros\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:45.672 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-92b' - ðŸ“¥ ExtraÃ­dos 100 registros\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:46.721 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'extract_data-92b' - Finished in state <span style=\"color: #008000; text-decoration-color: #008000\">Completed</span>()\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:46.721 | \u001b[36mINFO\u001b[0m    | Task run 'extract_data-92b' - Finished in state \u001b[32mCompleted\u001b[0m()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.699 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - Iniciando validaciÃ³n de datos\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.699 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - Iniciando validaciÃ³n de datos\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.706 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - DataFrame recibido con 100 registros y 5 columnas\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.706 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - DataFrame recibido con 100 registros y 5 columnas\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.712 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de cantidad de registros: OK (100 registros)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.712 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de cantidad de registros: OK (100 registros)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.727 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de valores nulos: OK (sin nulos)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.727 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de valores nulos: OK (sin nulos)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.733 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - Columnas requeridas faltantes: ['total']\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.733 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - Columnas requeridas faltantes: ['total']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.742 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - ValidaciÃ³n fallida con 1 error(es) crÃ­tico(s)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.742 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - ValidaciÃ³n fallida con 1 error(es) crÃ­tico(s)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:48.751 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - Task run failed with exception: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]') - Retry 1/1 will start 2 second(s) from now\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:48.751 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - Task run failed with exception: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]') - Retry 1/1 will start 2 second(s) from now\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.775 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - Iniciando validaciÃ³n de datos\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.775 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - Iniciando validaciÃ³n de datos\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.779 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - DataFrame recibido con 100 registros y 5 columnas\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.779 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - DataFrame recibido con 100 registros y 5 columnas\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.785 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de cantidad de registros: OK (100 registros)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.785 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de cantidad de registros: OK (100 registros)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.793 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de valores nulos: OK (sin nulos)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.793 | \u001b[36mINFO\u001b[0m    | Task run 'validate_data-885' - âœ… ValidaciÃ³n de valores nulos: OK (sin nulos)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.798 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - Columnas requeridas faltantes: ['total']\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.798 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - Columnas requeridas faltantes: ['total']\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.805 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - ValidaciÃ³n fallida con 1 error(es) crÃ­tico(s)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.805 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - ValidaciÃ³n fallida con 1 error(es) crÃ­tico(s)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:50.814 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - Task run failed with exception: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]') - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 869, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1505, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "    ~~~~~~~~~~~~~~~~~~~^^^^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 886, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\2533215734.py\", line 60, in validate_data\n",
       "    raise ValueError(f\"ValidaciÃ³n fallida: {errors}\")\n",
       "ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:50.814 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - Task run failed with exception: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]') - Retries are exhausted\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 869, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1505, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "    ~~~~~~~~~~~~~~~~~~~^^^^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 886, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\2533215734.py\", line 60, in validate_data\n",
       "    raise ValueError(f\"ValidaciÃ³n fallida: {errors}\")\n",
       "ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:51.939 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Task run 'validate_data-885' - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>('Task run encountered an exception ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:51.939 | \u001b[38;5;160mERROR\u001b[0m   | Task run 'validate_data-885' - Finished in state \u001b[38;5;160mFailed\u001b[0m('Task run encountered an exception ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:51.947 | <span style=\"color: #d70000; text-decoration-color: #d70000\">ERROR</span>   | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'copper-pudu'</span> - Encountered exception during execution: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 782, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1397, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "    ~~~~~~~~~~~~~~~~~~~^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 802, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\1903628702.py\", line 15, in etl_flow_with_validation\n",
       "    df_validated = validate_data(df_raw)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "        task=self,\n",
       "    ...&lt;2 lines&gt;...\n",
       "        return_type=return_type,\n",
       "    )\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1732, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1507, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ~~~~~~~~~~~~~^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 494, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 869, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1505, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "    ~~~~~~~~~~~~~~~~~~~^^^^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 886, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\2533215734.py\", line 60, in validate_data\n",
       "    raise ValueError(f\"ValidaciÃ³n fallida: {errors}\")\n",
       "ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:51.947 | \u001b[38;5;160mERROR\u001b[0m   | Flow run\u001b[35m 'copper-pudu'\u001b[0m - Encountered exception during execution: ValueError('ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n",
       "Traceback (most recent call last):\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 782, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 1397, in run_flow_sync\n",
       "    engine.call_flow_fn()\n",
       "    ~~~~~~~~~~~~~~~~~~~^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py\", line 802, in call_flow_fn\n",
       "    result = call_with_parameters(self.flow.fn, self.parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\1903628702.py\", line 15, in etl_flow_with_validation\n",
       "    df_validated = validate_data(df_raw)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\tasks.py\", line 1139, in __call__\n",
       "    return run_task(\n",
       "        task=self,\n",
       "    ...<2 lines>...\n",
       "        return_type=return_type,\n",
       "    )\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1732, in run_task\n",
       "    return run_task_sync(**kwargs)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1507, in run_task_sync\n",
       "    return engine.state if return_type == \"state\" else engine.result()\n",
       "                                                       ~~~~~~~~~~~~~^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 494, in result\n",
       "    raise self._raised\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 869, in run_context\n",
       "    yield self\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 1505, in run_task_sync\n",
       "    engine.call_task_fn(txn)\n",
       "    ~~~~~~~~~~~~~~~~~~~^^^^^\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py\", line 886, in call_task_fn\n",
       "    result = call_with_parameters(self.task.fn, parameters)\n",
       "  File \"c:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py\", line 210, in call_with_parameters\n",
       "    return fn(*args, **kwargs)\n",
       "  File \"C:\\Users\\juanp\\AppData\\Local\\Temp\\ipykernel_15420\\2533215734.py\", line 60, in validate_data\n",
       "    raise ValueError(f\"ValidaciÃ³n fallida: {errors}\")\n",
       "ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">17:21:52.037 | <span style=\"color: #008080; text-decoration-color: #008080\">INFO</span>    | Flow run<span style=\"color: #800080; text-decoration-color: #800080\"> 'copper-pudu'</span> - Finished in state <span style=\"color: #d70000; text-decoration-color: #d70000\">Failed</span>('Flow run encountered an exception: ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "17:21:52.037 | \u001b[36mINFO\u001b[0m    | Flow run\u001b[35m 'copper-pudu'\u001b[0m - Finished in state \u001b[38;5;160mFailed\u001b[0m('Flow run encountered an exception: ValueError: ValidaciÃ³n fallida: [\"Columnas faltantes: [\\'total\\']\"]')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Ejecutar el flow con validaciÃ³n\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m result = \u001b[43metl_flow_with_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸŽ‰ Flow con validaciÃ³n ejecutado exitosamente. Resultado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flows.py:1702\u001b[39m, in \u001b[36mFlow.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1698\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters)\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mflow_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_flow\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_flow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:1554\u001b[39m, in \u001b[36mrun_flow\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, error_logger, context)\u001b[39m\n\u001b[32m   1552\u001b[39m         ret_val = run_flow_async(**kwargs)\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m         ret_val = \u001b[43mrun_flow_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1555\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (Abort, Pause):\n\u001b[32m   1556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:1399\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1396\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m   1397\u001b[39m             engine.call_flow_fn()\n\u001b[32m-> \u001b[39m\u001b[32m1399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:361\u001b[39m, in \u001b[36mFlowRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# This is a fall through case which leans on the existing state result mechanics to get the\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# return value. This is necessary because we currently will return a State object if the\u001b[39;00m\n\u001b[32m    366\u001b[39m \u001b[38;5;66;03m# the State was Prefect-created.\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# TODO: Remove the need to get the result from a State except in cases where the return value\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;66;03m# is a State object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:782\u001b[39m, in \u001b[36mFlowRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    775\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m timeout_context(\n\u001b[32m    776\u001b[39m         seconds=\u001b[38;5;28mself\u001b[39m.flow.timeout_seconds,\n\u001b[32m    777\u001b[39m         timeout_exc_type=FlowRunTimeoutError,\n\u001b[32m    778\u001b[39m     ):\n\u001b[32m    779\u001b[39m         \u001b[38;5;28mself\u001b[39m.logger.debug(\n\u001b[32m    780\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuting flow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for flow run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.flow_run.name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:1397\u001b[39m, in \u001b[36mrun_flow_sync\u001b[39m\u001b[34m(flow, flow_run, parameters, wait_for, return_type, context)\u001b[39m\n\u001b[32m   1395\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m engine.is_running():\n\u001b[32m   1396\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m engine.run_context():\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_flow_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\flow_engine.py:802\u001b[39m, in \u001b[36mFlowRunEngine.call_flow_fn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    800\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_flow_fn()\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m802\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    803\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_success(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36metl_flow_with_validation\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     11\u001b[39m df_raw = extract_data()\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Paso 2: Validar datos (EXTENSIÃ“N DATAOPS)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Esta validaciÃ³n asegura que los datos cumplen con las expectativas antes de transformar\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m df_validated = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Paso 3: Transformar datos (solo si la validaciÃ³n pasa)\u001b[39;00m\n\u001b[32m     18\u001b[39m df_transformed = transform_data(df_validated)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\tasks.py:1139\u001b[39m, in \u001b[36mTask.__call__\u001b[39m\u001b[34m(self, return_state, wait_for, *args, **kwargs)\u001b[39m\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m track_viz_task(\n\u001b[32m   1134\u001b[39m         \u001b[38;5;28mself\u001b[39m.isasync, \u001b[38;5;28mself\u001b[39m.name, parameters, \u001b[38;5;28mself\u001b[39m.viz_return_value\n\u001b[32m   1135\u001b[39m     )\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mprefect\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtask_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_task\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:1732\u001b[39m, in \u001b[36mrun_task\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1730\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m run_task_async(**kwargs)\n\u001b[32m   1731\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1732\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_task_sync\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:1507\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1500\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1501\u001b[39m             engine.asset_context(),\n\u001b[32m   1502\u001b[39m             engine.run_context(),\n\u001b[32m   1503\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1504\u001b[39m         ):\n\u001b[32m   1505\u001b[39m             engine.call_task_fn(txn)\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:494\u001b[39m, in \u001b[36mSyncTaskRunEngine.result\u001b[39m\u001b[34m(self, raise_on_failure)\u001b[39m\n\u001b[32m    491\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m NotSet:\n\u001b[32m    492\u001b[39m     \u001b[38;5;66;03m# if the task raised an exception, raise it\u001b[39;00m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failure:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n\u001b[32m    496\u001b[39m     \u001b[38;5;66;03m# otherwise, return the exception\u001b[39;00m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raised\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:869\u001b[39m, in \u001b[36mSyncTaskRunEngine.run_context\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    866\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_cancelled():\n\u001b[32m    867\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m CancelledError(\u001b[33m\"\u001b[39m\u001b[33mTask run cancelled by the task runner\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m    870\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    871\u001b[39m     \u001b[38;5;28mself\u001b[39m.handle_timeout(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:1505\u001b[39m, in \u001b[36mrun_task_sync\u001b[39m\u001b[34m(task, task_run_id, task_run, parameters, wait_for, return_type, dependencies, context)\u001b[39m\n\u001b[32m   1499\u001b[39m         run_coro_as_sync(engine.wait_until_ready())\n\u001b[32m   1500\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[32m   1501\u001b[39m             engine.asset_context(),\n\u001b[32m   1502\u001b[39m             engine.run_context(),\n\u001b[32m   1503\u001b[39m             engine.transaction_context() \u001b[38;5;28;01mas\u001b[39;00m txn,\n\u001b[32m   1504\u001b[39m         ):\n\u001b[32m-> \u001b[39m\u001b[32m1505\u001b[39m             \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_task_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtxn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m engine.state \u001b[38;5;28;01mif\u001b[39;00m return_type == \u001b[33m\"\u001b[39m\u001b[33mstate\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m engine.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\task_engine.py:886\u001b[39m, in \u001b[36mSyncTaskRunEngine.call_task_fn\u001b[39m\u001b[34m(self, transaction)\u001b[39m\n\u001b[32m    884\u001b[39m     result = transaction.read()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m     result = \u001b[43mcall_with_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[38;5;28mself\u001b[39m.handle_success(result, transaction=transaction)\n\u001b[32m    888\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\juanp\\OneDrive - Universidad CatÃ³lica del Uruguay\\UCU\\Semestre 4\\IngenierÃ­a de Datos\\portafolio-ia\\.ven\\Lib\\site-packages\\prefect\\utilities\\callables.py:210\u001b[39m, in \u001b[36mcall_with_parameters\u001b[39m\u001b[34m(fn, parameters)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03mCall a function with parameters extracted with `get_call_parameters`\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    207\u001b[39m \u001b[33;03mthe args/kwargs using `parameters_to_positional_and_keyword` directly\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m args, kwargs = parameters_to_args_kwargs(fn, parameters)\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errors:\n\u001b[32m     59\u001b[39m     logger.error(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidaciÃ³n fallida con \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(errors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m error(es) crÃ­tico(s)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValidaciÃ³n fallida: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merrors\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     62\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mâœ… ValidaciÃ³n exitosa - Todos los checks pasaron\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mValueError\u001b[39m: ValidaciÃ³n fallida: [\"Columnas faltantes: ['total']\"]"
     ]
    }
   ],
   "source": [
    "# Ejecutar el flow con validaciÃ³n\n",
    "result = etl_flow_with_validation()\n",
    "print(f\"\\nðŸŽ‰ Flow con validaciÃ³n ejecutado exitosamente. Resultado: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25b499",
   "metadata": {},
   "source": [
    "## Parte 7 â€” ReflexiÃ³n y ConexiÃ³n con DataOps (5 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c44906",
   "metadata": {},
   "source": [
    "### 7.1 Conceptos de Prefect\n",
    "\n",
    "**1. Â¿CÃ³mo ayuda Prefect a implementar el principio de \"Observabilidad\" de DataOps?**\n",
    "\n",
    "**Respuesta:** Prefect implementa observabilidad de mÃºltiples formas:\n",
    "- **Logging estructurado**: Los logs de Prefect capturan automÃ¡ticamente el estado, tiempo de ejecuciÃ³n y mensajes de cada task\n",
    "- **Estados de ejecuciÃ³n**: Cada task tiene estados claros (PENDING, RUNNING, COMPLETED, FAILED) que se pueden monitorear\n",
    "- **UI centralizada**: Prefect Cloud/Server proporciona una interfaz visual para monitorear todos los flows y tasks en tiempo real\n",
    "- **MÃ©tricas**: Prefect rastrea mÃ©tricas como tiempo de ejecuciÃ³n, tasa de Ã©xito, y frecuencias de fallo\n",
    "- **Notificaciones**: Permite configurar alertas cuando los flows fallan\n",
    "\n",
    "Esto permite que los equipos de datos tengan visibilidad completa sobre sus pipelines, facilitando el debugging y la detecciÃ³n temprana de problemas.\n",
    "\n",
    "**2. Â¿CÃ³mo ayuda el caching a la \"Reproducibilidad\"?**\n",
    "\n",
    "**Respuesta:** El caching en Prefect ayuda a la reproducibilidad de varias formas:\n",
    "- **Resultados consistentes**: Al cachear resultados basados en parÃ¡metros, aseguras que las mismas entradas produzcan los mismos resultados\n",
    "- **Traza de ejecuciones**: Prefect mantiene un historial de ejecuciones cacheadas, permitiendo reproducir estados anteriores\n",
    "- **Puntos de recuperaciÃ³n**: Si un pipeline falla, puedes reutilizar resultados cacheados de tasks exitosas anteriores\n",
    "- **ValidaciÃ³n**: Permite comparar resultados actuales con resultados cacheados para detectar cambios inesperados\n",
    "\n",
    "Esto es fundamental en DataOps donde necesitas garantizar que los pipelines produzcan resultados consistentes y reproducibles.\n",
    "\n",
    "**3. Â¿CÃ³mo conectan los Deployments con \"CI/CD para datos\"?**\n",
    "\n",
    "**Respuesta:** Los Deployments en Prefect son el equivalente a \"releases\" en CI/CD tradicional:\n",
    "- **Versionado**: Los deployments permiten versionar y desplegar diferentes versiones de flows\n",
    "- **AutomatizaciÃ³n**: Los schedules permiten automatizar la ejecuciÃ³n de pipelines, similar a pipelines de CI/CD\n",
    "- **Ambientes**: Puedes tener diferentes deployments para desarrollo, staging y producciÃ³n\n",
    "- **Rollback**: Puedes cambiar quÃ© versiÃ³n de un flow estÃ¡ activa, permitiendo rollback rÃ¡pido\n",
    "- **IntegraciÃ³n con CI/CD**: Prefect puede integrarse con sistemas de CI/CD (GitHub Actions, GitLab CI) para desplegar automÃ¡ticamente cambios en los flows\n",
    "\n",
    "Esto permite aplicar prÃ¡cticas de DevOps a los pipelines de datos, facilitando despliegues seguros y controlados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b276ad08",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta tarea aprendimos:\n",
    "\n",
    "1. **Conceptos fundamentales** de Prefect: Tasks, Flows, DAGs implÃ­citos, estados, y caching\n",
    "2. **ImplementaciÃ³n prÃ¡ctica** de un pipeline ETL completo con Prefect\n",
    "3. **Funcionalidades avanzadas**: Retries, logging estructurado, validaciÃ³n de datos\n",
    "4. **Deployments y scheduling**: CÃ³mo desplegar y programar pipelines en producciÃ³n\n",
    "5. **ConexiÃ³n con DataOps**: CÃ³mo Prefect habilita observabilidad, reproducibilidad y CI/CD para datos\n",
    "\n",
    "Prefect es una herramienta poderosa para orquestar pipelines de datos de manera moderna, con una curva de aprendizaje suave y excelente integraciÃ³n con el ecosistema Python.\n",
    "\n",
    "---\n",
    "\n",
    "**Referencias:**\n",
    "- [DocumentaciÃ³n oficial de Prefect](https://docs.prefect.io/)\n",
    "- [Prefect Concepts Overview](https://docs.prefect.io/latest/concepts/)\n",
    "- [Prefect GitHub Examples](https://github.com/PrefectHQ/prefect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a0e09",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e99fb",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065bebce",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
