---
title: "Pr√°ctica 9 ‚Äî Target Encoding sobre sueldo de Adultos"
date: 2025-10-22
author: "Juan Paroli"
---

# üíµ Target Encoding sobre sueldo de Adultos: comparando t√©cnicas de encoding para variables categ√≥ricas

## Contexto

En esta pr√°ctica se aborda c√≥mo **predecir** si el ingreso anual de una persona supera 50k$ bas√°ndose en datos del censo. El **dataset Adult** abarca un censo del 1994 de Estados Unidos con **32,561 registros**, y es un dataset cl√°sico del Machine Learning y benchmarking. Se comparan distintas t√©cnicas de encoding para maximizar la precisi√≥n del modelo de clasificaci√≥n, explorando las ventajas y limitaciones de cada m√©todo seg√∫n la cardinalidad de las variables categ√≥ricas.

> **Objetivo**: identificar la t√©cnica de encoding m√°s adecuada seg√∫n la cardinalidad de las variables y demostrar la importancia de prevenir data leakage al usar t√©cnicas como Target Encoding.

Esta pr√°ctica fue desarrollada en un notebook de jupyter que puedes encontrar [aqu√≠](nueve.ipynb)

---

## Objetivos

- [x] Identificar relaciones de las variables con el target.
- [x] Comparar diferentes t√©cnicas de encoding (Label, One-Hot, Target Encoding).
- [x] Encontrar restricciones en aplicaciones como OneHotEncoding para variables de alta cardinalidad.
- [x] Evaluar el impacto de cada t√©cnica en el rendimiento del modelo.

---

## Desarrollo

### 1. Setup y carga de datos

**Setup**
- Fuente: UCI `adult` (32,561 filas).
- Librer√≠as: `pandas`, `numpy`, `scikit-learn`, `category_encoders`, `matplotlib`, `seaborn`.
- Distribuci√≥n del target:
  - Menores a 50k de ingresos: **24,720 (75.9%)**
  - Mayores a 50K de ingresos: **7,841 (24.1%)**

**Proceso**
- Carga del dataset desde UCI Machine Learning Repository.
- An√°lisis inicial de estructura y distribuci√≥n de clases.
- Identificaci√≥n de variables categ√≥ricas y num√©ricas.

**Resultados clave**
- **Se√±ales clave**: No hay valores faltantes en el dataset.
- Dataset desbalanceado con 75.9% de clase mayoritaria (ingresos ‚â§50k).
- 8 variables categ√≥ricas y 6 variables num√©ricas identificadas.

### 2. An√°lisis de cardinalidad

**Proceso**
- An√°lisis de cada variable categ√≥rica para determinar su cardinalidad.
- Clasificaci√≥n de variables seg√∫n cardinalidad (baja, media, alta).
- Identificaci√≥n de problemas potenciales con One-Hot Encoding.

**Resultados clave**

Variables categ√≥ricas encontradas: **8**

`workclass`, `education`, `marital-status`, `occupation`, `relationship`, `race`, `sex` y `native-country`

**Clasificaci√≥n de cardinalidad**

Se clasific√≥ la cardinalidad de las features como:
- **Baja** ‚â§ 10
- **Media** 10 < cardinalidad ‚â§ 40
- **Alta** > 40

**Distribuci√≥n de variables por cardinalidad**:
- `workclass`: **9 categor√≠as √∫nicas** (BAJA)
- `education`: **16 categor√≠as √∫nicas** (MEDIA)
- `marital-status`: **7 categor√≠as √∫nicas** (BAJA)
- `occupation`: **15 categor√≠as √∫nicas** (MEDIA)
- `relationship`: **6 categor√≠as √∫nicas** (BAJA)
- `race`: **5 categor√≠as √∫nicas** (BAJA)
- `sex`: **2 categor√≠as √∫nicas** (BAJA)
- `native-country`: **42 categor√≠as √∫nicas** (ALTA)

**Problema de dimensionalidad con OneHotEncoding**:

- workclass: 9 categor√≠as ‚Üí **8 columnas one-hot**
- education: 16 categor√≠as ‚Üí **15 columnas one-hot**
- marital-status: 7 categor√≠as ‚Üí **6 columnas one-hot**
- occupation: 15 categor√≠as ‚Üí **14 columnas one-hot**
- relationship: 6 categor√≠as ‚Üí **5 columnas one-hot**
- race: 5 categor√≠as ‚Üí **4 columnas one-hot**
- sex: 2 categor√≠as ‚Üí **1 columna one-hot**
- native-country: 42 categor√≠as ‚Üí **41 columnas one-hot**

**Total**: ~94 columnas adicionales solo para variables categ√≥ricas.

One-hot encoding **NO** es viable para variables de alta cardinalidad (como `native-country`). Por lo tanto, necesitamos t√©cnicas alternativas:
- **Label Encoding**
- **Target Encoding**
- **Hash Encoding**
- **Binary Encoding**

![](results/cardinal-analisis.png)

### 3. Label Encoding

**Setup**
- T√©cnica: Label Encoding aplicado a todas las variables categ√≥ricas.
- Modelo: RandomForestClassifier.
- M√©tricas: Accuracy, AUC-ROC, F1-Score.

**Proceso**
- Aplicaci√≥n de Label Encoding a 8 variables categ√≥ricas.
- Entrenamiento de RandomForest con todas las features.
- Evaluaci√≥n del rendimiento del modelo.

**Resultados clave**

Label Encoding aplicado a **8 features categ√≥ricas**. Los resultados obtenidos fueron:

- üìä **Accuracy**: **0.8632**
- üìä **AUC-ROC**: **0.9101**
- üìä **F1-Score**: **0.6931**
- ‚è±Ô∏è **Training time**: **0.77s**

**Ventajas**: Simple, r√°pido, no aumenta la dimensionalidad.

**Desventajas**: Puede introducir relaciones ordinales artificiales entre categor√≠as que no la tienen.

### 4. One-Hot Encoding para features con baja cardinalidad

**Setup**
- T√©cnica: One-Hot Encoding aplicado √∫nicamente a variables con baja cardinalidad.
- Modelo: RandomForestClassifier.
- Justificaci√≥n: Evitar explosi√≥n dimensional con variables de alta cardinalidad.

**Proceso**
- Identificaci√≥n de variables con baja cardinalidad (‚â§10).
- Aplicaci√≥n de OHE solo a estas variables.
- Entrenamiento y evaluaci√≥n del modelo.

**Resultados clave**

Los resultados obtenidos son levemente peores en comparaci√≥n a Label Encoding:

- üìä **Accuracy**: **0.8483**
- üìä **AUC-ROC**: **0.8995**
- üìä **F1-Score**: **0.6633**
- ‚è±Ô∏è **Training time**: **0.67s**

**An√°lisis**: Aunque OHE mantiene la interpretabilidad, no mejora el rendimiento en este caso y aumenta la dimensionalidad.

### 5. Target Encoding con alta cardinalidad

**Setup**
- T√©cnica: Target Encoding aplicado a `native-country` (alta cardinalidad).
- Prevenci√≥n de leakage: Uso de cross-validation para prevenir data leakage.
- Modelo: RandomForestClassifier.

**Proceso**
- Aplicaci√≥n de Target Encoding a `native-country` con validaci√≥n cruzada.
- Combinaci√≥n con otras t√©cnicas de encoding para variables de baja/media cardinalidad.
- Entrenamiento y evaluaci√≥n del modelo.

**Resultados clave**

Entrenamos un Random Forest y estos fueron los resultados obtenidos:

- üìä **Accuracy**: **0.8092**
- üìä **AUC-ROC**: **0.8318**
- üìä **F1-Score**: **0.5658**
- ‚è±Ô∏è **Training time**: **1.63s**

**An√°lisis**: Target Encoding result√≥ √∫til pero menos destacable aqu√≠ por la ausencia de columnas con muchas categor√≠as realmente problem√°ticas. El tiempo de entrenamiento aument√≥ debido al proceso de cross-validation.

### 6. An√°lisis de Feature Importance con Pipeline Branching

**Setup**
- Pipeline con branching de 3 ramas:
  - Rama 1: One-Hot para baja cardinalidad (5 cols)
  - Rama 2: Target Encoding para alta cardinalidad (1 col)
  - Rama 3: StandardScaler para num√©ricas (6 cols)
- Modelo: RandomForestClassifier.

**Proceso**
- Implementaci√≥n de pipeline modular con ColumnTransformer.
- Entrenamiento del modelo con todas las transformaciones.
- An√°lisis de importancia de features.

**Resultados clave**

Este Pipeline generaba una cantidad de columnas nuevas considerable. Partiendo de un total de **12 Features originales**, la transformaci√≥n gener√≥ un total de **31 features** que se puede considerar de **dimensionalidad media**.

Entrenamos un Random Forest con estas Features y los resultados obtenidos fueron:

- üìä **Accuracy**: **0.8488**
- üìä **AUC-ROC**: **0.9021**
- üìä **F1-Score**: **0.6671**
- ‚è±Ô∏è **Training time**: **2.08s**

**Top Features (feature importance)**

| Rank | Feature                  | Importance |
|-----:|:-------------------------|-----------:|
| 1    | num__fnlwgt              | 0.223091   |
| 2    | num__age                 | 0.165969   |
| 3    | num__education-num       | 0.132941   |
| 4    | num__capital-gain        | 0.114665   |
| 5    | num__hours-per-week      | 0.092367   |

![](results/feature_importance.png)

**An√°lisis de resultados**

Las **variables m√°s importantes** seg√∫n el an√°lisis de feature importance fueron principalmente **num√©ricas**, destac√°ndose:
- `fnlwgt`
- `age`
- `education-num`
- `capital-gain`
- `hours-per-week`

Estas concentraron m√°s del **75% de la importancia total del modelo**, lo que muestra que las variables continuas aportan la mayor capacidad predictiva sobre los ingresos.

**Hallazgo importante**: No hubo variables de alta cardinalidad (target encoded) relevantes en este caso, ya que el dataset Adult Income pr√°cticamente no conten√≠a variables realmente problem√°ticas en t√©rminos de cardinalidad.

**Desde una perspectiva anal√≠tica y de negocio**:
- Los factores que m√°s predicen el ingreso son edad, nivel educativo, tipo de empleo y capital acumulado, lo que coincide con patrones socioecon√≥micos reales.
- Las categor√≠as relacionadas con el estado civil tambi√©n inciden, lo que puede reflejar correlaciones indirectas con estabilidad laboral o responsabilidades familiares.
- Para aplicaciones pr√°cticas, esto implica que los modelos predictivos de ingresos pueden simplificarse priorizando las variables num√©ricas, reduciendo complejidad sin perder rendimiento.
- Adem√°s, es importante considerar posibles sesgos de g√©nero o de relaci√≥n familiar, ya que el modelo podr√≠a reproducir desigualdades presentes en los datos originales del censo.

---

## üìÅ Evidencias

### An√°lisis de cardinalidad

**Visualizaci√≥n de cardinalidad por variable categ√≥rica**

![](results/cardinal-analisis.png)

### An√°lisis de importancia de features

**Top features seg√∫n importancia**

![](results/feature_importance.png)

### C√≥digo de ejemplo: Pipeline con Branching

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from category_encoders import TargetEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline

# Definir transformadores por tipo
preprocessor = ColumnTransformer(
    transformers=[
        ('onehot', OneHotEncoder(), low_cardinality_features),
        ('target', TargetEncoder(), high_cardinality_features),
        ('scaler', StandardScaler(), numeric_features)
    ]
)

# Pipeline completo
pipeline = Pipeline([
    ('preprocessor', preprocessor),
    ('model', RandomForestClassifier())
])
```

---

## üí° Reflexi√≥n

### Aprendizajes clave

- **No siempre la complejidad garantiza mejor rendimiento**: A pesar de probar estrategias de codificaci√≥n m√°s elaboradas (Target Encoding, branching pipelines), los resultados muestran que las **variables num√©ricas** concentran la mayor parte del poder predictivo.
- **Label Encoding emerge como opci√≥n eficiente**: Cuando el modelo no asume relaciones lineales estrictas (como los √°rboles de decisi√≥n), Label Encoding evita la explosi√≥n dimensional y mantiene una excelente capacidad predictiva.
- **One-Hot Encoding es √∫til pero limitado**: Es √∫til en variables de baja cardinalidad y mantiene interpretabilidad, aunque penaliza en escalabilidad cuando el n√∫mero de categor√≠as crece.
- **Target Encoding requiere manejo cuidadoso**: Si bien te√≥ricamente m√°s informativo para variables de alta cardinalidad, requiere una estructura de datos m√°s compleja y un manejo cuidadoso del data leakage mediante cross-validation.
- **Pipelines combinados aportan modularidad**: Los pipelines con branching aportan modularidad y reproducibilidad, pero su ventaja pr√°ctica solo se justifica en escenarios con estructuras mixtas de datos o cardinalidades extremas.

### Limitaciones y desaf√≠os

- **El dataset no ten√≠a variables realmente problem√°ticas**: La falta de columnas con cardinalidad extremadamente alta limit√≥ la demostraci√≥n del valor de Target Encoding.
- **Variables num√©ricas dominan**: Las variables num√©ricas originales dominaron claramente el modelo, tanto en importancia total como promedio, limitando el impacto de las t√©cnicas de encoding.
- **Trade-off entre complejidad y rendimiento**: En t√©rminos de m√©tricas, las diferencias fueron peque√±as entre m√©todos, lo que sugiere que la complejidad adicional no siempre se justifica.

### Pr√≥ximos pasos

- Explorar otros m√©todos de encoding (Hash Encoding, Binary Encoding, Entity Embeddings).
- Probar con datasets que tengan variables de cardinalidad extremadamente alta.
- Evaluar el impacto de encoding en modelos lineales (que son m√°s sensibles a la representaci√≥n de variables categ√≥ricas).
- Investigar t√©cnicas de embedding para variables categ√≥ricas de alta cardinalidad.

!!! warning "Atenci√≥n"
    **La clave no est√° en usar el encoding m√°s avanzado, sino en usar el m√°s adecuado.** La explicabilidad, la alineaci√≥n con el contexto del negocio y la prevenci√≥n del sobreajuste son tan importantes como la m√©trica final de performance.

---

## üìö Referencias

- **Dua, D., & Graff, C. (2019)**. *UCI Machine Learning Repository ‚Äî Adult Data Set.* University of California, Irvine.
  [https://archive.ics.uci.edu/ml/datasets/adult](https://archive.ics.uci.edu/ml/datasets/adult)

- **Micci-Barreca, D. (2001)**. *A Preprocessing Scheme for High-Cardinality Categorical Attributes in Classification and Prediction Problems.* SIGKDD Explorations, 3(1), 27‚Äì32.

- **Lema√Ætre, G., Nogueira, F., & Aridas, C. K. (2017)**. *Imbalanced-learn: A Python Toolbox to Tackle the Curse of Imbalanced Datasets in Machine Learning.* Journal of Machine Learning Research, 18(17), 1‚Äì5.

- **Scikit-learn Developers (2024)**. *User Guide: Encoding categorical features.*
  [https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features)

- **Category Encoders (2017‚Äì2024)**. *Official Documentation ‚Äî TargetEncoder, OrdinalEncoder, OneHotEncoder.*
  [https://contrib.scikit-learn.org/category_encoders/](https://contrib.scikit-learn.org/category_encoders/)

- **Lundberg, S. M., & Lee, S.-I. (2017)**. *A Unified Approach to Interpreting Model Predictions (SHAP).* Advances in Neural Information Processing Systems (NeurIPS).
  [https://arxiv.org/abs/1705.07874](https://arxiv.org/abs/1705.07874)

- **Kaggle (2023)**. *Adult Census Income Prediction ‚Äî Benchmark Notebook.*
  [https://www.kaggle.com/uciml/adult-census-income](https://www.kaggle.com/uciml/adult-census-income)

- **Notebook completo**: [nueve.ipynb](nueve.ipynb)

---
