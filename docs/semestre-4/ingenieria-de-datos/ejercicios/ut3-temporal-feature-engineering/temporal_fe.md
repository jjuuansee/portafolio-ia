---
title: "Pr√°ctica 11 ‚Äî Temporal Feature Engineering: Extracci√≥n y An√°lisis de Variables Temporales"
date: 2025-11-03
author: "Juan Paroli"
---

# ‚è∞ Temporal Feature Engineering: Optimizando modelos de predicci√≥n de recompra

## Contexto

En esta pr√°ctica se trabaj√≥ con el **dataset Online Retail de Kaggle**, que contiene **397,884 transacciones** de compras en l√≠nea realizadas por **4,338 clientes** durante el per√≠odo **2010-2011**. El objetivo fue explorar patrones temporales en el comportamiento de compra y crear **37 features temporales** que representen la frecuencia, recurrencia y h√°bitos de los usuarios a lo largo del tiempo, aplic√°ndolas a un modelo de predicci√≥n de recompra (`will_purchase_again`).

> El an√°lisis fue desarrollado en un notebook de Jupyter que puedes encontrar [aqu√≠](11_temporal-fe.ipynb)

## üéØ Objetivos

- [x] Cargar y limpiar un dataset transaccional real (Online Retail de Kaggle).
- [x] Comprender la estructura temporal de los datos y evitar data leakage.
- [x] Crear variables de tiempo a nivel de transacci√≥n y de usuario.
- [x] Implementar Lag Features con `.groupby()` + `.shift()` para prevenir data leakage.
- [x] Calcular Rolling Window Features (media y desviaci√≥n est√°ndar m√≥vil).
- [x] Calcular Expanding Window Features (comportamiento hist√≥rico acumulado).
- [x] Implementar RFM Analysis (Recency, Frequency, Monetary).
- [x] Crear Time Window Aggregations (7d, 30d, 90d).
- [x] Calcular Product Diversity Features.
- [x] Implementar Calendar Features con encoding c√≠clico (sin/cos).
- [x] Integrar External Variables (indicadores econ√≥micos simulados).
- [x] Evaluar performance con TimeSeriesSplit y comparar modelo base vs modelo con temporal features.
- [x] Analizar importancia de features por categor√≠a.
- [x] Implementar t√©cnicas avanzadas de validaci√≥n (Blocked, Walk-Forward, Purged K-Fold).

## Desarrollo

### 1. Setup y carga de datos

Se descarg√≥ el dataset Online Retail desde Kaggle mediante la API. El dataset contiene informaci√≥n de facturas, productos, cantidades, precios y clientes.

**Resultados del preprocesamiento:**

- **Shape inicial**: (541,909, 8) registros
- **Filas despu√©s de limpieza**: 397,884 (eliminaci√≥n de nulos, cancelaciones, valores ‚â§ 0)
- **Rango temporal**: 2010-12-01 a 2011-12-09 (373 d√≠as)
- **Usuarios √∫nicos**: 4,338
- **Productos √∫nicos**: 3,665
- **√ìrdenes totales**: 18,532
- **Usuarios con m√∫ltiples √≥rdenes**: 2,845 (65.6%)
- **Promedio √≥rdenes por usuario**: 4.27
- **Promedio items por orden**: 21.47

![√ìrdenes por semana y distribuci√≥n de d√≠as entre √≥rdenes](results/ordenes_por_semana_y_dias_entre_ordenes.png)

**Insights iniciales:**

- Mediana de d√≠as entre √≥rdenes: **8 d√≠as**
- El dataset es ideal para temporal feature engineering (alta frecuencia de compras repetidas)

### 2. Creaci√≥n de features temporales b√°sicas

Se generaron variables a nivel de transacci√≥n y luego se agregaron a nivel de orden:

**Features a nivel de transacci√≥n:**

- `order_dow`: d√≠a de la semana (0 = lunes, 6 = domingo)
- `order_hour_of_day`: hora del d√≠a de la compra (0-23)

**Features a nivel de orden (agregaci√≥n):**

- `cart_size`: cantidad total de √≠tems en la orden
- `order_total`: gasto total
- `order_number`: n√∫mero secuencial de compra por usuario (1, 2, 3...)
- `days_since_prior_order`: d√≠as transcurridos desde la compra anterior

**Dataset agregado (`orders_df`):**

- **Shape**: (18,562, 9) - una fila por orden/factura
- **Usuarios √∫nicos**: 4,338
- **Cart size promedio**: 21.44 items
- **Total promedio por orden**: $193.50
- **D√≠as promedio entre √≥rdenes**: 18.5 d√≠as

### 3. Lag Features con Pandas

Se implementaron lag features usando `.groupby()` + `.shift()` para prevenir data leakage:

**Features creadas:**

- `days_since_prior_lag_1`: d√≠as desde la orden anterior (shift 1)
- `days_since_prior_lag_2`: d√≠as desde hace 2 √≥rdenes (shift 2)
- `days_since_prior_lag_3`: d√≠as desde hace 3 √≥rdenes (shift 3)

**Resultados:**

- NaNs en lag_1: 7,185 (38.7% - primera orden de cada usuario)
- NaNs en lag_2: 10,747 (57.9%)
- NaNs en lag_3: 12,429 (67.0%)

**Ejemplo para usuario 12748 (210 √≥rdenes):**

- Primera orden: todos los lags son NaN
- Segunda orden: lag_1 = 0.0 d√≠as, lag_2 y lag_3 = NaN
- Tercera orden: lag_1 = 3.0 d√≠as, lag_2 = 0.0 d√≠as, lag_3 = NaN

### 4. Rolling Window Features

Se calcularon ventanas m√≥viles de 3 √≥rdenes previas usando `.shift(1)` antes de `.rolling()`:

**Features creadas:**

- `rolling_cart_mean_3`: media m√≥vil de cart_size (√∫ltimas 3 √≥rdenes)
- `rolling_cart_std_3`: desviaci√≥n est√°ndar m√≥vil de cart_size

![Rolling Mean vs Actual Cart Size](results/rolling_mean_cart_size.png)

**Insight:** Las ventanas m√≥viles capturan tendencias recientes del comportamiento del usuario, permitiendo detectar cambios en patrones de compra.

### 5. Expanding Window Features

Se calcularon m√©tricas acumulativas desde el inicio del historial del usuario:

**Features creadas:**

- `expanding_days_mean`: media acumulativa de d√≠as entre √≥rdenes
- `expanding_total_spent`: gasto total acumulado
- `total_orders_so_far`: n√∫mero total de √≥rdenes hasta el momento

![Rolling y Expanding Mean](results/rolling_expanding_mean.png)

**Diferencia clave:**

- **Rolling**: √∫ltimos N eventos (tendencia reciente)
- **Expanding**: todos los eventos previos (comportamiento hist√≥rico)

### 6. RFM Analysis

Se implement√≥ an√°lisis RFM (Recency, Frequency, Monetary) para segmentar usuarios:

**Features creadas:**

- `recency_days`: d√≠as desde la √∫ltima compra
- `frequency_total_orders`: n√∫mero total de √≥rdenes del usuario
- `monetary_avg`: gasto promedio por orden
- `monetary_total`: gasto total acumulado

**Estad√≠sticas RFM:**

- Recency promedio: 160.5 d√≠as
- Frequency promedio: 8.6 √≥rdenes
- Monetary promedio: $1,882,507 por orden
- Monetary total promedio: $3,590,503

![An√°lisis RFM](results/rfm_analysis.png)

**Correlaci√≥n RFM:**

- Recency vs Frequency: -0.218 (negativa: usuarios m√°s recientes compran m√°s frecuentemente)
- Recency vs Monetary: 0.263 (positiva: usuarios m√°s recientes gastan m√°s)
- Frequency vs Monetary: -0.338 (negativa: usuarios que compran mucho gastan menos por orden)

### 7. Time Window Aggregations

Se calcularon agregaciones en ventanas temporales (7d, 30d, 90d) usando `closed='left'` para prevenir data leakage:

**Features creadas:**

- `orders_7d`, `orders_30d`, `orders_90d`: n√∫mero de √≥rdenes en cada ventana
- `spend_7d`, `spend_30d`, `spend_90d`: gasto total en cada ventana

**Resumen de ventanas temporales:**

- Promedio √≥rdenes 7d: 0.41
- Promedio √≥rdenes 30d: 1.42
- Promedio √≥rdenes 90d: 3.69
- Promedio spend 7d: $294.55
- Promedio spend 30d: $922.79
- Promedio spend 90d: $2,392.72

![Time Window Aggregations](results/time_windows_aggregations.png)

**Insight:** Comparar ventanas detecta usuarios 'activ√°ndose' o 'durmiendo' (cambios en comportamiento reciente vs hist√≥rico).

### 8. Product Diversity Features

Se calcularon m√©tricas de diversidad de productos comprados:

**Features creadas:**

- `unique_products`: n√∫mero de productos √∫nicos comprados
- `unique_countries`: n√∫mero de pa√≠ses desde donde compra (generalmente 1)
- `total_items`: total de items/l√≠neas compradas
- `product_diversity_ratio`: productos √∫nicos / total items (ratio de diversidad)

**Estad√≠sticas:**

- Productos √∫nicos promedio: 61.5
- Total items promedio: 91.7
- **Diversity ratio promedio: 0.85** (mediana: 0.91)

![Product Diversity](results/product_diversity.png)

**Interpretaci√≥n:**

- Ratio alto (~1.0): Usuario explora productos variados (alta diversidad, no recompra)
- Ratio bajo (<0.5): Usuario recompra frecuentemente (baja diversidad)

### 9. Calendar Features con Encoding C√≠clico

Se implementaron features de calendario con encoding c√≠clico (sin/cos) para preservar la naturaleza circular del tiempo:

**Features binarias:**

- `is_weekend`: flag de fin de semana
- `is_month_start`, `is_month_end`: flags de inicio/fin de mes
- `is_holiday`: flag de d√≠as festivos UK
- `days_to_holiday`: d√≠as hasta pr√≥ximo feriado

**Encoding c√≠clico:**

- `hour_sin`, `hour_cos`: encoding de hora del d√≠a (0-23)
- `dow_sin`, `dow_cos`: encoding de d√≠a de semana (0-6)
- `month_sin`, `month_cos`: encoding de mes (1-12)

![Encoding C√≠clico de Calendar Features](results/cyclic_encoding_calendar.png)

**Ventaja del encoding c√≠clico:**

- Las 23h est√°n 'cerca' de las 0h en el espacio sin/cos
- El domingo est√° 'cerca' del lunes
- El modelo captura mejor la continuidad temporal

**Efecto Weekend:**

- Cart size promedio en weekday vs weekend muestra diferencias significativas

### 10. Economic Indicators (Simulados)

Se integraron indicadores econ√≥micos mensuales simulados:

**Features creadas:**

- `gdp_growth`: crecimiento del PIB (%)
- `unemployment_rate`: tasa de desempleo (%)
- `consumer_confidence`: √≠ndice de confianza del consumidor

**Rangos:**

- GDP Growth: 2.27% a 3.29%
- Unemployment: 3.43% a 4.44%
- Consumer Confidence: 94.2 a 101.9

![Economic Features](results/economic_features.png)

**Regla de oro:** S√ìLO forward fill (ffill), NUNCA backward fill (bfill)

- Forward: usar informaci√≥n pasada para rellenar presente/futuro (OK)
- Backward: usar informaci√≥n futura para rellenar pasado (DATA LEAKAGE!)

### 11. Preparaci√≥n para Modeling

Se cre√≥ el target `will_purchase_again` (1 si el usuario hace otra compra despu√©s de esta orden, 0 si no):

**Resultados:**

- Target creado: 14,224 √≥rdenes seguidas de otra compra
- Total √≥rdenes: 18,562
- **Tasa de recompra: 76.6%**

**Dataset final para modeling:**

- **Shape**: (7,861, 40) despu√©s de eliminar NaN
- **Features disponibles**: 37 de 37 solicitadas
- **Target distribution**: 85.8% clase 1 (recompra), 14.2% clase 0 (no recompra)

**Features seleccionadas:**

- Lag features: 3
- Rolling features: 2
- Expanding features: 3
- RFM features: 3
- Time window features: 6
- Diversity features: 3
- Calendar features: 11
- Economic features: 3
- Base features: 3

### 12. TimeSeriesSplit Validation

Se implement√≥ validaci√≥n temporal con `TimeSeriesSplit` (3 folds):

**Resultados de Cross-Validation:**

| Fold | Train Size | Val Size | Train Dates | Val Dates | AUC |
|------|------------|----------|-------------|-----------|-----|
| 1 | 1,966 | 1,965 | 2010-12-01 to 2011-06-01 | 2011-06-01 to 2011-08-28 | 0.7598 |
| 2 | 3,931 | 1,965 | 2010-12-01 to 2011-08-28 | 2011-08-28 to 2011-11-02 | 0.7585 |
| 3 | 5,896 | 1,965 | 2010-12-01 to 2011-11-02 | 2011-11-02 to 2011-12-09 | 0.6644 |

**Mean AUC: 0.7276 ¬± 0.0547**

### 13. Comparaci√≥n: Con vs Sin Temporal Features

Se compar√≥ un modelo base (sin temporal features) vs modelo completo (con todas las temporal features):

**Resultados:**

| Modelo | Features | AUC Mean | AUC Std | Improvement |
|--------|----------|----------|----------|-------------|
| **Base Model** | 7 (solo calendar y base) | 0.6615 | ¬± 0.0223 | - |
| **Full Model** | 37 (con temporal features) | **0.7276** | ¬± 0.0446 | **+10.0%** |

![Model Performance Comparison](results/model_performance_comparison.png)

**Insight clave:** Las temporal features mejoran significativamente el performance del modelo (+10% en AUC).

### 14. Feature Importance Analysis

Se analiz√≥ la importancia de features usando Random Forest:

**Top 10 Features m√°s importantes:**

| Rank | Feature | Importance | Category |
|------|---------|------------|----------|
| 1 | `product_diversity_ratio` | 0.1039 | Diversity |
| 2 | `recency_days` | 0.0833 | RFM |
| 3 | `unique_products` | 0.0635 | Diversity |
| 4 | `spend_90d` | 0.0564 | Time Window |
| 5 | `days_since_prior_lag_3` | 0.0483 | Lag/Window |
| 6 | `days_since_prior_lag_1` | 0.0457 | Lag/Window |
| 7 | `order_total` | 0.0451 | Base |
| 8 | `days_since_prior_lag_2` | 0.0380 | Lag/Window |
| 9 | `rolling_cart_mean_3` | 0.0380 | Lag/Window |
| 10 | `monetary_avg` | 0.0357 | RFM |

**Importancia por categor√≠a:**

| Category | Sum Importance | Mean Importance | Count |
|----------|----------------|-----------------|-------|
| **Lag/Window** | 0.2904 | 0.0363 | 8 |
| **Diversity** | 0.1681 | 0.0560 | 3 |
| **RFM** | 0.1527 | 0.0509 | 3 |
| **Time Window** | 0.1379 | 0.0230 | 6 |
| **Base** | 0.0966 | 0.0322 | 3 |
| **Calendar** | 0.0954 | 0.0087 | 11 |
| **Economic** | 0.0589 | 0.0196 | 3 |

![Feature Importance Analysis](results/feature_importance_analysis.png)

**Insights:**

- **Lag/Window features** son las m√°s importantes (29% del total)
- **Diversity features** tienen alta importancia individual (ratio de diversidad es #1)
- **RFM** sigue siendo relevante (recency_days es #2)
- **Calendar features** tienen importancia baja pero distribuida (11 features)

### 15. Data Leakage Detection

Se realiz√≥ un an√°lisis exhaustivo para detectar data leakage:

**Verificaciones realizadas:**

  1. **Performance check:**
      - Train accuracy: 0.8811
      - CV AUC: 0.7276
      - ‚úÖ Performance looks reasonable (gap razonable)

  2. **Top feature check:**
     - Top 5: `['product_diversity_ratio', 'recency_days', 'unique_products', 'spend_90d', 'days_since_prior_lag_3']`
     - ‚úÖ No obviously suspicious features
   
  3. **Temporal consistency:**
      - Fold 1: ‚ö†Ô∏è LEAKAGE: Train includes dates from validation period! (coincidencia exacta de fechas)
      - Fold 2: ‚úÖ Train max < Val min
      - Fold 3: ‚úÖ Train max < Val min

  4. **Feature calculation check:**
      - ‚úÖ Todas las aggregations usan `shift(1)`
      - ‚úÖ TimeSeriesSplit usado en lugar de KFold
      - ‚úÖ Solo forward fill (no backward fill)
      - ‚úÖ Rolling windows con `closed='left'`

**Conclusi√≥n:** No hay leakage estructural, solo una superposici√≥n m√≠nima en el primer fold que no afecta significativamente.

### 16. T√©cnicas Avanzadas de Validaci√≥n

Se implementaron tres t√©cnicas avanzadas de validaci√≥n temporal:

#### 16.1 Blocked Time Series Cross-Validation

Se introdujo un gap temporal de 100 observaciones entre train y validaci√≥n:

**Resultados:**

- Fold 1: Train=1,866, Val=1,965, AUC=0.7780
- Fold 2: Train=3,831, Val=1,965, AUC=0.8116
- Fold 3: Train=5,796, Val=1,965, AUC=0.7070
- **Promedio AUC (Blocked): 0.7655**

**Interpretaci√≥n:** El modelo mantiene rendimiento s√≥lido incluso con el gap, demostrando que las temporal features tienen poder predictivo sostenido.

#### 16.2 Walk-Forward Validation

Se reprodujo el flujo real de predicci√≥n en producci√≥n:

**Resultados:**

- Fold 1: Train hasta 2011-06-01 | Val desde 2011-06-01 | AUC=0.7598
- Fold 2: Train hasta 2011-08-28 | Val desde 2011-08-28 | AUC=0.7585
- Fold 3: Train hasta 2011-11-02 | Val desde 2011-11-02 | AUC=0.6644
- **Promedio AUC (Walk-Forward): 0.7276**

**Interpretaci√≥n:** Garantiza consistencia temporal total, manteniendo AUC similar al original.

#### 16.3 Purged K-Fold

Se implement√≥ purga de ¬±7 d√≠as alrededor de la ventana de validaci√≥n y embargo del 5% del train:

**Resultados:**

- Fold 1: Train=1,769 (raw=1,966, purged=1,863) | Val=1,965 | AUC=0.7155
- Fold 2: Train=3,550 (raw=3,931, purged=3,737) | Val=1,965 | AUC=0.7860
- Fold 3: Train=5,348 (raw=5,896, purged=5,630) | Val=1,965 | AUC=0.7028
- **AUC Promedio: 0.7348 ¬± 0.0448**

**Interpretaci√≥n:** M√©todo m√°s estricto y robusto, reduce riesgo de leakage sin deteriorar rendimiento significativamente.

## Evidencias

### C√≥digo de creaci√≥n de Lag Features

```python
# Lag Features con Pandas - Previene data leakage
orders_df['days_since_prior_lag_1'] = (
    orders_df.groupby('user_id')['days_since_prior_order']
    .shift(1)  # CR√çTICO: shift(1) previene data leakage
)

orders_df['days_since_prior_lag_2'] = (
    orders_df.groupby('user_id')['days_since_prior_order']
    .shift(2)
)

orders_df['days_since_prior_lag_3'] = (
    orders_df.groupby('user_id')['days_since_prior_order']
    .shift(3)
)
```

**Output:**
```
‚úÖ Lag Features creadas con Pandas
‚úÖ NaNs en lag_1: 7,185 (38.7% - primera orden de cada usuario)
üí° .groupby() + .shift() previene data leakage: cada usuario tiene sus propios lags independientes
```

### C√≥digo de Rolling Window Features

```python
# Rolling Window Features - Con shift(1) para prevenir leakage
orders_df['rolling_cart_mean_3'] = (
    orders_df.groupby('user_id')['cart_size']
    .shift(1)  # Excluir orden actual
    .rolling(window=3, min_periods=1)
    .mean()
)

orders_df['rolling_cart_std_3'] = (
    orders_df.groupby('user_id')['cart_size']
    .shift(1)
    .rolling(window=3, min_periods=1)
    .std()
)
```

**Output:**
```
‚úÖ Rolling Features creadas con Pandas
‚úÖ Ventaja clave: .shift(1) antes de .rolling() previene data leakage autom√°ticamente
```

### C√≥digo de TimeSeriesSplit Validation

```python
from sklearn.model_selection import TimeSeriesSplit

n_splits = 3
tscv = TimeSeriesSplit(n_splits=n_splits)

for fold, (train_idx, val_idx) in enumerate(tscv.split(X), 1):
    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
    
    model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
    model.fit(X_train, y_train)
    
    y_pred_proba = model.predict_proba(X_val)[:, 1]
    auc = roc_auc_score(y_val, y_pred_proba)
    
    print(f"Fold {fold}: AUC={auc:.4f}")
```

**Output:**
```
=== TIME SERIES CROSS-VALIDATION ===
--- Fold 1/3 ---
Train: 2010-12-01 to 2011-06-01 (1,966 samples)
Val:   2011-06-01 to 2011-08-28 (1,965 samples)
Validation AUC: 0.7598

--- Fold 2/3 ---
Train: 2010-12-01 to 2011-08-28 (3,931 samples)
Val:   2011-08-28 to 2011-11-02 (1,965 samples)
Validation AUC: 0.7585

--- Fold 3/3 ---
Train: 2010-12-01 to 2011-11-02 (5,896 samples)
Val:   2011-11-02 to 2011-12-09 (1,965 samples)
Validation AUC: 0.6644

Mean AUC: 0.7276 ¬± 0.0547
```

### Comparaci√≥n de Modelos

**Resultados finales:**

```
=== FEATURE COMPARISON ===
Base features: 7
   ['order_dow', 'order_hour_of_day', 'is_weekend', 'is_holiday', 'cart_size']...
Temporal features: 30
   ['days_since_prior_lag_1', 'days_since_prior_lag_2', 'days_since_prior_lag_3', 
    'rolling_cart_mean_3', 'rolling_cart_std_3']...
Total features: 37

=== RESULTS ===
Base Model (no temporal):  AUC = 0.6615 ¬± 0.0223
Full Model (con temporal): AUC = 0.7276 ¬± 0.0446
Improvement: 0.0661 (10.0%)
```

## Reflexi√≥n

### Lecciones aprendidas

1. **Temporal features mejoran significativamente el performance**: El modelo con temporal features obtuvo un AUC de 0.7276 vs 0.6615 del modelo base, una mejora del 10%.

2. **Lag y window features capturan patrones de comportamiento**: Las features de lag y ventanas m√≥viles fueron las m√°s importantes (29% del total), demostrando que el comportamiento hist√≥rico es clave para predecir recompra.

3. **RFM analysis sigue siendo relevante en e-commerce**: `recency_days` fue la segunda feature m√°s importante (0.0833), confirmando que el tiempo desde la √∫ltima compra es un predictor fuerte.

4. **TimeSeriesSplit es cr√≠tico para evitar data leakage**: La validaci√≥n temporal garantiza que el modelo no use informaci√≥n futura, esencial en problemas de series temporales.

5. **External variables pueden agregar valor**: Aunque las features econ√≥micas tuvieron importancia baja, pueden ser √∫tiles en contextos espec√≠ficos.

6. **Diversity features son muy informativas**: `product_diversity_ratio` fue la feature m√°s importante (0.1039), indicando que los usuarios que exploran productos variados tienen diferente comportamiento de recompra.

### Prevenci√≥n de Data Leakage con Pandas

Las mejores pr√°cticas implementadas:

- ‚úÖ **Siempre usar `.groupby() + .shift(1)` antes de aggregations**: Previene que la orden actual se incluya en c√°lculos hist√≥ricos
- ‚úÖ **TimeSeriesSplit para cross-validation**: Garantiza que validaci√≥n siempre sea posterior a entrenamiento
- ‚úÖ **Solo forward fill (nunca backward)**: Usar informaci√≥n pasada para rellenar presente/futuro es seguro
- ‚úÖ **Rolling temporal con `closed='left'`**: Excluye el evento actual de la ventana
- ‚úÖ **Verificar que val dates > train dates**: Validaci√≥n temporal estricta

### Desaf√≠os encontrados

1. **Manejo de NaN en lag features**: Las primeras √≥rdenes de cada usuario generan NaN en los lags, requiriendo estrategias de imputaci√≥n o eliminaci√≥n.

2. **Balanceo de clases**: El target tiene 85.8% de clase 1 (recompra), lo que puede sesgar el modelo hacia predecir siempre recompra.

3. **Superposici√≥n temporal m√≠nima**: El primer fold de TimeSeriesSplit mostr√≥ una coincidencia exacta de fechas entre train y validation, aunque el impacto fue m√≠nimo.

### Aplicaciones futuras

Este enfoque puede aplicarse a:

- **Sistemas de recomendaci√≥n**: Predecir qu√© productos comprar√° un usuario
- **Churn prediction**: Identificar usuarios en riesgo de abandonar
- **Marketing personalizado**: Segmentar usuarios por comportamiento temporal
- **Forecasting de demanda**: Predecir demanda futura basada en patrones hist√≥ricos

## Conclusi√≥n

Las **temporal features** permiten capturar el ritmo de interacci√≥n de los usuarios con el sistema y aportan un valor significativo para modelos de predicci√≥n de comportamiento. Este trabajo demostr√≥ que:

1. **Las temporal features mejoran el performance en 10%** (AUC: 0.6615 ‚Üí 0.7276)
2. **Lag/Window features son las m√°s importantes** (29% del total de importancia)
3. **RFM analysis sigue siendo relevante** (recency_days es la segunda feature m√°s importante)
4. **La prevenci√≥n de data leakage es cr√≠tica** y requiere t√©cnicas espec√≠ficas para series temporales
5. **Las t√©cnicas avanzadas de validaci√≥n** (Blocked, Walk-Forward, Purged) proporcionan estimaciones m√°s robustas

El trabajo reforz√≥ la comprensi√≥n del flujo temporal en los datos y la forma correcta de generar variables que respeten la naturaleza temporal de los eventos, evitando data leakage y maximizando el poder predictivo del modelo.

## Referencias

- **Dataset**: [Online Retail Dataset (Kaggle)](https://www.kaggle.com/datasets/vijayuv/onlineretail)
- [Documentaci√≥n Pandas ‚Äì Time Series / Shift / Diff](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html)
- [Scikit-learn: TimeSeriesSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html)
- [Feature Engineering for Machine Learning - Temporal Features](https://www.oreilly.com/library/view/feature-engineering-for/9781491953235/)
- [Preventing Data Leakage in Time Series](https://www.kaggle.com/code/ryanholbrook/preventing-data-leakage-in-time-series)
